{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets first connect to the wed driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\karishma yadav\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"014f8167b3c0355ce4186aeed1a56725\", element=\"94c60712-4050-414e-ab98-ac14f6bddb57\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job location bar\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "job_titles=[]\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst - Data Lineage',\n",
       " 'Data Analyst - Informatica MDM',\n",
       " 'Data analysts',\n",
       " 'Excel VBA Jobs Bangalore | VBA data analyst Jobs',\n",
       " 'Data Analyst (2positions)//immediate Joiners//bangalore',\n",
       " 'Business/Data Analyst - SSE/LA',\n",
       " 'Business Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - Category Demand Management (Revenue & Growth)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for i in title[:10]:\n",
    "    job_titles.append(i.text)    \n",
    "job_titles    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mysore/Mysuru, Coimbatore, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the tags having job_location\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "job_location=[]\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location[:10]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "LOCATION=job_location[:10]\n",
    "print(len(LOCATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having company names\n",
    "name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Opex Global Services',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Mind Circus Innovation',\n",
       " 'Tech Mahindra Ltd.',\n",
       " 'CGI Information Systems and Management Consultants',\n",
       " 'dotSolved India Pvt., Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'Myntra Designs Pvt. Ltd.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "company_name=[]\n",
    "for i in name[:10]:\n",
    "    company_name.append(i.text)\n",
    "company_name    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags having the experience required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having experience data\n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-10 Yrs',\n",
       " '6-9 Yrs',\n",
       " '3-5 Yrs',\n",
       " '0-1 Yrs',\n",
       " '4-8 Yrs',\n",
       " '2-5 Yrs',\n",
       " '9-13 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '1-4 Yrs']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "experience_required=[]\n",
    "for i in experience[:10]:\n",
    "    experience_required.append(i.text)\n",
    "experience_required    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the location of the job data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# checking the length\n",
    "print(len(job_titles),len(company_name),len(experience_required),len(LOCATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a DataFrame\n",
    "a={\"Job_Title\": job_titles,\"Company_Name\": company_name,\"Experience_Required\": experience_required,\"Job_location\":job_location}\n",
    "jobs_data=pd.DataFrame.from_dict(a, orient='index')\n",
    "jobs_data=jobs_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst - Data Lineage</td>\n",
       "      <td>Opex Global Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excel VBA Jobs Bangalore | VBA data analyst Jobs</td>\n",
       "      <td>Mind Circus Innovation</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Mysore/Mysuru, Coimbatore, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst (2positions)//immediate Joiners//...</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business/Data Analyst - SSE/LA</td>\n",
       "      <td>CGI Information Systems and Management Consult...</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>dotSolved India Pvt., Ltd.</td>\n",
       "      <td>9-13 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Category Demand Management (Rev...</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                 Senior Data Analyst - Data Lineage   \n",
       "1                     Data Analyst - Informatica MDM   \n",
       "2                                      Data analysts   \n",
       "3   Excel VBA Jobs Bangalore | VBA data analyst Jobs   \n",
       "4  Data Analyst (2positions)//immediate Joiners//...   \n",
       "5                     Business/Data Analyst - SSE/LA   \n",
       "6                              Business Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9  Data Analyst - Category Demand Management (Rev...   \n",
       "\n",
       "                                        Company_Name Experience_Required  \\\n",
       "0                               Opex Global Services            5-10 Yrs   \n",
       "1                Shell India Markets Private Limited             6-9 Yrs   \n",
       "2                             IBM India Pvt. Limited             3-5 Yrs   \n",
       "3                             Mind Circus Innovation             0-1 Yrs   \n",
       "4                                 Tech Mahindra Ltd.             4-8 Yrs   \n",
       "5  CGI Information Systems and Management Consult...             2-5 Yrs   \n",
       "6                         dotSolved India Pvt., Ltd.            9-13 Yrs   \n",
       "7                           Myntra Designs Pvt. Ltd.             3-5 Yrs   \n",
       "8                           Myntra Designs Pvt. Ltd.             3-8 Yrs   \n",
       "9                           Myntra Designs Pvt. Ltd.             1-4 Yrs   \n",
       "\n",
       "                                       Job_location  \n",
       "0                               Bangalore/Bengaluru  \n",
       "1                               Bangalore/Bengaluru  \n",
       "2                               Bangalore/Bengaluru  \n",
       "3    Mysore/Mysuru, Coimbatore, Bangalore/Bengaluru  \n",
       "4                               Bangalore/Bengaluru  \n",
       "5                               Bangalore/Bengaluru  \n",
       "6  Chennai, Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "7                               Bangalore/Bengaluru  \n",
       "8                               Bangalore/Bengaluru  \n",
       "9                               Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5c2ce2f8f36f5aee0b463e043cccdd23\", element=\"ef457bb5-2a29-4279-b081-c0f07e74d9dc\")>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "Search_field=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "Search_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "Search_field.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "Search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function\n",
    "Search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Senior Data Scientist',\n",
       " 'Immediate job opening - Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'VP - Sr. Data Scientist For Morgan Stanley, Bangalore',\n",
       " 'Lead Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Data analytics / Data scientist intern (work from Home)',\n",
       " 'Data Scientist - IBM Garage',\n",
       " 'Digital Enterprise Architect (Data Scientist)']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "job_titles=[]\n",
    "for i in Title[:10]:\n",
    "    job_titles.append(i.text)\n",
    "job_titles    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Kolkata, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location[:10]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Kolkata, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having company names\n",
    "Name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'RedBus',\n",
       " 'Fractal Analytics',\n",
       " 'Morgan Stanley Advantage Services',\n",
       " 'FICO',\n",
       " 'Fractal Analytics',\n",
       " 'Global Talent Pool',\n",
       " 'TalkValley LLC',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Mphasis Limited']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Company_name=[]\n",
    "for i in Name[:10]:\n",
    "    Company_name.append(i.text)\n",
    "Company_name    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags having the experience required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having experience data\n",
    "Experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '5-8 Yrs',\n",
       " '5-9 Yrs',\n",
       " '8-13 Yrs',\n",
       " '6-11 Yrs',\n",
       " '10-15 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-5 Yrs',\n",
       " '2-6 Yrs',\n",
       " '10-13 Yrs']"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Experience_required=[]\n",
    "for i in Experience[:10]:\n",
    "    Experience_required.append(i.text)\n",
    "Experience_required    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract all the html tags where we have the location of the job data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_description.append(description)\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 30 10\n"
     ]
    }
   ],
   "source": [
    "# checking the length\n",
    "print(len(job_titles),len(Company_name),len(job_location),len(job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a DataFrame for our data\n",
    "a={\"Job_Title\": JOB_titles,\"Company_Name\": Company_name,\"Experience_Required\": Experience,\"Job_location\":job_location,\"Salary\": job_salary,\"Job Description\":job_description}\n",
    "jobs_scientist_Bangolre=pd.DataFrame.from_dict(a, orient='index')\n",
    "jobs_scientist_Bangolre=jobs_scientist_Bangolre.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "      <td>Job description\\nJob Role : Data Scientist/Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2,00,000 - 3,00,000 PA.</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job description\\nServe as primary technical le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job description\\nAbout Us\\nMorgan Stanley is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are hiring- Data Scientist +Python- Noida</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job description\\nJob Summary\\nThe candidate sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Milliman India Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job description\\nPosition Description:\\nThe Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job description\\nWe are a group of tenured pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Scientist Big Data, Statistical T...</td>\n",
       "      <td>The Search House (A Div of JSD Search House Pv...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>5,00,000 - 8,00,000 PA.</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3,50,000 - 6,50,000 PA.</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Data analytics / Data scientist intern (work f...   \n",
       "2                                     Data Scientist   \n",
       "3              Chaayos is Looking For Data Scientist   \n",
       "4                              Junior Data Scientist   \n",
       "5       We are hiring- Data Scientist +Python- Noida   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Data Analyst/Scientist Big Data, Statistical T...   \n",
       "9                   Business Analyst- Data Scientist   \n",
       "\n",
       "                                        Company_Name Experience_Required  \\\n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "1                                     TalkValley LLC             0-5 Yrs   \n",
       "2                                  Fractal Analytics             3-7 Yrs   \n",
       "3              Chaayos (Sunshine Teahouse Pvt. Ltd.)             0-5 Yrs   \n",
       "4                       R Systems International Ltd.             3-5 Yrs   \n",
       "5                             RANDSTAD INDIA PVT LTD             4-7 Yrs   \n",
       "6                             Milliman India Pvt Ltd             2-5 Yrs   \n",
       "7              NEC CORPORATION INDIA PRIVATE LIMITED             3-8 Yrs   \n",
       "8  The Search House (A Div of JSD Search House Pv...             2-7 Yrs   \n",
       "9                                              Wipro             2-5 Yrs   \n",
       "\n",
       "                                        Job_location                   Salary  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  3,50,000 - 4,50,000 PA.   \n",
       "1                                Bangalore/Bengaluru  2,00,000 - 3,00,000 PA.   \n",
       "2                                Bangalore/Bengaluru            Not disclosed   \n",
       "3      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru            Not disclosed   \n",
       "4                                Bangalore/Bengaluru            Not disclosed   \n",
       "5                                Bangalore/Bengaluru            Not disclosed   \n",
       "6  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...            Not disclosed   \n",
       "7          Kolkata, Bangalore/Bengaluru, Delhi / NCR            Not disclosed   \n",
       "8                                Bengaluru/Bangalore  5,00,000 - 8,00,000 PA.   \n",
       "9                                Bangalore/Bengaluru  3,50,000 - 6,50,000 PA.   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job description\\nJob Role : Data Scientist/Dat...  \n",
       "1                                      Not Available  \n",
       "2                                      Not Available  \n",
       "3  Job description\\nServe as primary technical le...  \n",
       "4  Job description\\nAbout Us\\nMorgan Stanley is a...  \n",
       "5  Job description\\nJob Summary\\nThe candidate sh...  \n",
       "6  Job description\\nPosition Description:\\nThe Ar...  \n",
       "7  Job description\\nWe are a group of tenured pro...  \n",
       "8                                      Not Available  \n",
       "9                                      Not Available  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_scientist_Bangolre[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ee9673c55a5aa95afdb3eaddff241ee4\", element=\"96f9ac52-168d-4aaf-bc45-45d52722ae5b\")>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys(\"Data Scientist, Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do click using xpath function\n",
    "Search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Machine Learning/APICS']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "job_titles1=[]\n",
    "for i in Title[:1]:\n",
    "    job_titles1.append(i.text)\n",
    "job_titles1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_description.append(description)\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "g=job_description[:10]\n",
    "print(len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Machine Learning']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "job_titles2=[]\n",
    "for i in Title[1:2]:\n",
    "    job_titles2.append(i.text)\n",
    "job_titles2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist, Machine Learning']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "job_titles3=[]\n",
    "for i in Title[2:3]:\n",
    "    job_titles3.append(i.text)\n",
    "job_titles3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Algorithm/ Machine Learning']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "job_titles4=[]\n",
    "for i in Title[3:4]:\n",
    "    job_titles4.append(i.text)\n",
    "job_titles4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Image Processing/ Machine Learning']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "job_titles5=[]\n",
    "for i in Title[4:5]:\n",
    "    job_titles5.append(i.text)\n",
    "job_titles5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Image Processing/Machine Learning']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the tags having the job_titles\n",
    "job_titles6=[]\n",
    "for i in Title[5:6]:\n",
    "    job_titles6.append(i.text)\n",
    "job_titles6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Artificial Intelligence/ Machine Learning']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the tags having the job_titles\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles7=[]\n",
    "for i in Title[6:7]:\n",
    "    job_titles7.append(i.text)\n",
    "job_titles7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Machine Learning']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the tags having the job_titles\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles8=[]\n",
    "for i in Title[7:8]:\n",
    "    job_titles8.append(i.text)\n",
    "job_titles8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Machine/deep Learning Algorithms']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the tags having the job_titles\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles9=[]\n",
    "for i in Title[8:9]:\n",
    "    job_titles9.append(i.text)\n",
    "job_titles9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Artificial Intelligence/Machine Learning']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles10=[]\n",
    "for i in Title[9:10]:\n",
    "    job_titles10.append(i.text)\n",
    "job_titles10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Machine Learning/APICS',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist, Machine Learning',\n",
       " 'Data Scientist - Algorithm/ Machine Learning',\n",
       " 'Data Scientist - Image Processing/ Machine Learning',\n",
       " 'Data Scientist - Image Processing/Machine Learning',\n",
       " 'Data Scientist - Artificial Intelligence/ Machine Learning',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist - Machine/deep Learning Algorithms',\n",
       " 'Data Scientist - Artificial Intelligence/Machine Learning']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=['Data Scientist - Machine Learning/APICS','Data Scientist - Machine Learning','Data Scientist, Machine Learning','Data Scientist - Algorithm/ Machine Learning','Data Scientist - Image Processing/ Machine Learning','Data Scientist - Image Processing/Machine Learning','Data Scientist - Artificial Intelligence/ Machine Learning','Data Scientist - Machine Learning','Data Scientist - Machine/deep Learning Algorithms','Data Scientist - Artificial Intelligence/Machine Learning']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# checking the length\n",
    "print(len(job_titles),len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Job_Titles</th>\n",
       "      <td>Data Scientist - Machine Learning/APICS</td>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Data Scientist, Machine Learning</td>\n",
       "      <td>Data Scientist - Algorithm/ Machine Learning</td>\n",
       "      <td>Data Scientist - Image Processing/ Machine Lea...</td>\n",
       "      <td>Data Scientist - Image Processing/Machine Lear...</td>\n",
       "      <td>Data Scientist - Artificial Intelligence/ Mach...</td>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Data Scientist - Machine/deep Learning Algorithms</td>\n",
       "      <td>Data Scientist - Artificial Intelligence/Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job_description</th>\n",
       "      <td>Job description\\nJob Role : Data Scientist/Dat...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Job description\\nServe as primary technical le...</td>\n",
       "      <td>Job description\\nAbout Us\\nMorgan Stanley is a...</td>\n",
       "      <td>Job description\\nJob Summary\\nThe candidate sh...</td>\n",
       "      <td>Job description\\nPosition Description:\\nThe Ar...</td>\n",
       "      <td>Job description\\nWe are a group of tenured pro...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 0  \\\n",
       "Job_Titles                 Data Scientist - Machine Learning/APICS   \n",
       "Job_description  Job description\\nJob Role : Data Scientist/Dat...   \n",
       "\n",
       "                                                 1  \\\n",
       "Job_Titles       Data Scientist - Machine Learning   \n",
       "Job_description                      Not Available   \n",
       "\n",
       "                                                2  \\\n",
       "Job_Titles       Data Scientist, Machine Learning   \n",
       "Job_description                     Not Available   \n",
       "\n",
       "                                                                 3  \\\n",
       "Job_Titles            Data Scientist - Algorithm/ Machine Learning   \n",
       "Job_description  Job description\\nServe as primary technical le...   \n",
       "\n",
       "                                                                 4  \\\n",
       "Job_Titles       Data Scientist - Image Processing/ Machine Lea...   \n",
       "Job_description  Job description\\nAbout Us\\nMorgan Stanley is a...   \n",
       "\n",
       "                                                                 5  \\\n",
       "Job_Titles       Data Scientist - Image Processing/Machine Lear...   \n",
       "Job_description  Job description\\nJob Summary\\nThe candidate sh...   \n",
       "\n",
       "                                                                 6  \\\n",
       "Job_Titles       Data Scientist - Artificial Intelligence/ Mach...   \n",
       "Job_description  Job description\\nPosition Description:\\nThe Ar...   \n",
       "\n",
       "                                                                 7  \\\n",
       "Job_Titles                       Data Scientist - Machine Learning   \n",
       "Job_description  Job description\\nWe are a group of tenured pro...   \n",
       "\n",
       "                                                                 8  \\\n",
       "Job_Titles       Data Scientist - Machine/deep Learning Algorithms   \n",
       "Job_description                                      Not Available   \n",
       "\n",
       "                                                                 9  \n",
       "Job_Titles       Data Scientist - Artificial Intelligence/Machi...  \n",
       "Job_description                                      Not Available  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a DataFrame for our data\n",
    "job_scientist_data={\"Job_Titles\":df,\"Job_description\":g}\n",
    "job_scientist_data=pd.DataFrame.from_dict(job_scientist_data, orient='index')\n",
    "job_scientist_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"7c06e7e3e947abe8580cdb6751a6cdf6\", element=\"37f08a83-3b2f-461d-98e8-88563c51ac3a\")>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job location bar\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Delhi/NCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # finding element for search button\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_salary=driver.find_element_by_xpath('//span[@title=\\\"3-6 Lakhs\\\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-data-scientist-data-analyst-business-analyst-inflexion-analytix-private-limited-mumbai-hyderabad-secunderabad-pune-gurgaon-gurugram-chennai-bangalore-bengaluru-0-to-3-years-100521000368?src=jobsearchDesk&sid=16237467739554180&xp=1&px=1\n",
      "Exception Raised:  Message: stale element reference: element is not attached to the page document\n",
      "  (Session info: chrome=91.0.4472.101)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/data-scientist-jobs-in-delhi-ncr?k=data%20scientist&l=delhi%2Fncr\")\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "try:\n",
    "    for i in urls[0:3]:\n",
    "        print(i.get_attribute('href'))\n",
    "        driver.get(i.get_attribute('href'))\n",
    "except StaleElementReferenceException as e:\n",
    "    print(\"Exception Raised: \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data analytics / Data scientist intern (work from Home)',\n",
       " 'Data Scientist',\n",
       " 'Chaayos is Looking For Data Scientist',\n",
       " 'Junior Data Scientist',\n",
       " 'We are hiring- Data Scientist +Python- Noida',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Analyst/Scientist Big Data, Statistical Techniques',\n",
       " 'Business Analyst- Data Scientist']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "JOB_titles=[]\n",
    "for i in Titles[:10]:\n",
    "    JOB_titles.append(i.text)\n",
    "JOB_titles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having company names\n",
    "Name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'TalkValley LLC',\n",
       " 'Fractal Analytics',\n",
       " 'Chaayos (Sunshine Teahouse Pvt. Ltd.)',\n",
       " 'R Systems International Ltd.',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'Milliman India Pvt Ltd',\n",
       " 'NEC CORPORATION INDIA PRIVATE LIMITED',\n",
       " 'The Search House (A Div of JSD Search House Pvt. L td.)',\n",
       " 'Wipro']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "# Let's create empty list for storing the data\n",
    "Company_name=[]\n",
    "for i in Name[:10]:\n",
    "    Company_name.append(i.text)\n",
    "Company_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'New Delhi',\n",
       " 'Noida(Sector-59 Noida)',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Noida',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Noida, Gurgaon/Gurugram']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "job_location[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "LOCATION=job_description[:10]\n",
    "print(len(LOCATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having experience data\n",
    "Experience=[]\n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '0-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '0-5 Yrs',\n",
       " '3-5 Yrs',\n",
       " '4-7 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-7 Yrs',\n",
       " '2-5 Yrs']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for i in experience[:10]:\n",
    "    Experience.append(i.text)\n",
    "Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "salary=driver.find_elements_by_xpath('//li[@class=\\\"fleft grey-text br2 placeHolderLi salary\\\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,50,000 - 4,50,000 PA.',\n",
       " '2,00,000 - 3,00,000 PA.',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " '5,00,000 - 8,00,000 PA.',\n",
       " '3,50,000 - 6,50,000 PA.']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "job_salary=[]\n",
    "for i in salary[:10]:\n",
    "    job_salary.append(i.text)\n",
    "job_salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# checking the length\n",
    "print(len(JOB_titles),len(Company_name))\n",
    "print(len(LOCATION),len(job_salary),len(Experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's create a DataFrame for our data\n",
    "a={\"Job_Title\": JOB_titles,\"Company_Name\": Company_name,\"Experience_Required\": Experience,\"Job_location\":job_location,\"Salary\": job_salary}\n",
    "jobs_scientist_jobs=pd.DataFrame.from_dict(a, orient='index')\n",
    "jobs_scientist_jobs=jobs_scientist_jobs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>2,00,000 - 3,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are hiring- Data Scientist +Python- Noida</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Milliman India Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Scientist Big Data, Statistical T...</td>\n",
       "      <td>The Search House (A Div of JSD Search House Pv...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>5,00,000 - 8,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "      <td>3,50,000 - 6,50,000 PA.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Data analytics / Data scientist intern (work f...   \n",
       "2                                     Data Scientist   \n",
       "3              Chaayos is Looking For Data Scientist   \n",
       "4                              Junior Data Scientist   \n",
       "5       We are hiring- Data Scientist +Python- Noida   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Data Analyst/Scientist Big Data, Statistical T...   \n",
       "9                   Business Analyst- Data Scientist   \n",
       "\n",
       "                                        Company_Name Experience_Required  \\\n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs   \n",
       "1                                     TalkValley LLC             0-5 Yrs   \n",
       "2                                  Fractal Analytics             3-7 Yrs   \n",
       "3              Chaayos (Sunshine Teahouse Pvt. Ltd.)             0-5 Yrs   \n",
       "4                       R Systems International Ltd.             3-5 Yrs   \n",
       "5                             RANDSTAD INDIA PVT LTD             4-7 Yrs   \n",
       "6                             Milliman India Pvt Ltd             2-5 Yrs   \n",
       "7              NEC CORPORATION INDIA PRIVATE LIMITED             3-8 Yrs   \n",
       "8  The Search House (A Div of JSD Search House Pv...             2-7 Yrs   \n",
       "9                                              Wipro             2-5 Yrs   \n",
       "\n",
       "                                        Job_location                   Salary  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  3,50,000 - 4,50,000 PA.  \n",
       "1          Kolkata, Bangalore/Bengaluru, Delhi / NCR  2,00,000 - 3,00,000 PA.  \n",
       "2      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru            Not disclosed  \n",
       "3                                          New Delhi            Not disclosed  \n",
       "4                             Noida(Sector-59 Noida)            Not disclosed  \n",
       "5               Noida, Gurgaon/Gurugram, Delhi / NCR            Not disclosed  \n",
       "6                      Gurgaon/Gurugram, Delhi / NCR            Not disclosed  \n",
       "7                                              Noida            Not disclosed  \n",
       "8                                   Gurgaon/Gurugram  5,00,000 - 8,00,000 PA.  \n",
       "9                            Noida, Gurgaon/Gurugram  3,50,000 - 6,50,000 PA.  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_scientist_jobs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.glassdoor.co.in/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "def glass_door_job(url):\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    job_title=[]\n",
    "    company_name=[]\n",
    "    rating=[]\n",
    "    days=[]\n",
    "    temp = []\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # If we visit the glassdoor page we will observe that, to navigate into the page we have to do the login\n",
    "    # Let's click on the sign-in butoon for logining\n",
    "    #driver.find_element_by_xpath('//*[@id=\"SiteNav\"]/nav/div[1]/div[1]/button').click()\n",
    "\n",
    "        \n",
    "    #Let's enter the demo login details\n",
    "    driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('glassdoortestassignment@gmail.com')\n",
    "    driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('Assignment@1234')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's maximize the window size because there are some text font size is will has other element details in short window\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "    driver.maximize_window()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's fill the requied details in search column and click search\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys('Noida (India)')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's search the desired detail which we hve entered\n",
    "    driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    jobs=driver.find_elements_by_xpath('//article[@id=\"MainCol\"]/div/ul/li')\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"JAModal\"]/div/div[2]/span').click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        job.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "        # Let's scrape the data\n",
    "        job_title.append((driver.find_element_by_xpath('//div[@class=\"css-1vg6q84 e1tk4kwz4\"]')).text)\n",
    "        temp.append((driver.find_element_by_xpath('//div[@class=\"css-87uc0g e1tk4kwz1\"]')).text.replace('\\n',''))\n",
    "        for i in temp:\n",
    "            for j in i:\n",
    "                res = ''.join(j for j in i if not j.isdigit())\n",
    "                fin = res.replace('.', '')\n",
    "            company_name.append(fin)\n",
    "        try:\n",
    "            rating.append((driver.find_element_by_xpath('//span[@data-test=\"detailRating\"]')).text)\n",
    "        except:\n",
    "            rating.append('NA')\n",
    "        try:\n",
    "            days.append((driver.find_element_by_xpath('//div[@data-test=\"job-age\"]')).text)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    job_glass_door=pd.DataFrame({})\n",
    "    job_glass_door['Job Title']=job_title[0:10]\n",
    "    job_glass_door['Company Name']=company_name[0:10]\n",
    "    job_glass_door['Ratings']=rating[0:10]\n",
    "    job_glass_door['Job Posted']=days[0:10]\n",
    "    return job_glass_door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@id=\"userEmail\"]\"}\n  (Session info: chrome=91.0.4472.106)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b29f51b86950>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mglass_door_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.glassdoor.co.in/Salaries/index.htm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-d5de98f6087d>\u001b[0m in \u001b[0;36mglass_door_job\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#Let's enter the demo login details\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//input[@id=\"userEmail\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'glassdoortestassignment@gmail.com'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//input[@id=\"userPassword\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Assignment@1234'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@id=\"userEmail\"]\"}\n  (Session info: chrome=91.0.4472.106)\n"
     ]
    }
   ],
   "source": [
    "glass_door_job('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_salary_full(url):\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    gd_min_salary=[]\n",
    "    gd_max_salary=[]\n",
    "    gd_avg_salary=[]\n",
    "    gd_company_name=[]\n",
    "    gd_rating=[]\n",
    "    #temp=[]\n",
    "\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #Let's navigate to search bar and then type the Data Scientist job, location Noida and then click search button\n",
    "    driver.find_element_by_xpath('//*[@id=\"KeywordSearch\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys('Noida (India)')\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-btn-mkt\"]').click()\n",
    "    time.sleep(8)\n",
    "    \n",
    "    #Let's search the element for required details\n",
    "    companies=driver.find_elements_by_xpath('//div[@data-test=\"job-info\"]/p[2]')\n",
    "    avg_salary=driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]/strong')\n",
    "    min_salary=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]/span[1]')\n",
    "    max_salary=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]/span[2]')\n",
    "#     rating='NA'\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    for i in companies:\n",
    "        gd_company_name.append(i.text)\n",
    "    for i in avg_salary:\n",
    "        gd_avg_salary.append(i.text)\n",
    "    for i in min_salary:\n",
    "        gd_min_salary.append(i.text)\n",
    "    for i in max_salary:\n",
    "        gd_max_salary.append(i.text)\n",
    "        \n",
    "    # Let's create a DataFrame for our data\n",
    "    salaries=pd.DataFrame({})\n",
    "    salaries['Company Name']=gd_company_name[:10]\n",
    "    salaries['Avgerage Salary']=gd_avg_salary[:10]\n",
    "    salaries['Minimum Salary']=gd_min_salary[:10]\n",
    "    salaries['Maximum Salary']=gd_max_salary[:10]\n",
    "    \n",
    "    driver.get('https://www.glassdoor.co.in/profile/login_input.htm?userOriginHook=HEADER_SIGNIN_LINK')\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('glassdoortestassignment@gmail.com')\n",
    "    driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('Assignment@1234')\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "    time.sleep(10)\n",
    "    for i in gd_company_name[:11]:\n",
    "        driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]').send_keys(i)\n",
    "        driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.CONTROL+'a')\n",
    "        driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button').click()\n",
    "        time.sleep(8)\n",
    "        try:\n",
    "            gd_rating.append((driver.find_element_by_xpath('//span[@data-test=\"detailRating\"]')).text.replace('\\n', ''))\n",
    "        except:\n",
    "            gd_rating.append('NA')\n",
    "        time.sleep(7)   \n",
    "        driver.back()\n",
    "        time.sleep(5) \n",
    "    \n",
    "    salaries['Rating']=gd_rating[:10]\n",
    "    \n",
    "    return salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Avgerage Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company Name, Avgerage Salary, Minimum Salary, Maximum Salary, Rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_salary_full('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's navigate to search bar\n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_sunglasses(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    #Let's navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's search for sunglasses product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sunglasses')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    sunglass_brand_name=[]\n",
    "    sunglass_description=[]\n",
    "    sunglass_price=[]\n",
    "    sunglass_discount=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sunglass_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sunglass_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sunglass_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sunglass_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    # Let's create a DataFrame for our data   \n",
    "    sunglasses_flip=pd.DataFrame({})\n",
    "    sunglasses_flip['Product Brand']=sunglass_brand_name[:100]\n",
    "    sunglasses_flip['Product Description']=sunglass_description[:100]\n",
    "    sunglasses_flip['Price of Product']=sunglass_price[:100]\n",
    "    sunglasses_flip['Discount on Product']=sunglass_discount[:100]\n",
    "    return sunglasses_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price of Product</th>\n",
       "      <th>Discount on Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>541</td>\n",
       "      <td>32% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>537</td>\n",
       "      <td>32% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (50)</td>\n",
       "      <td>331</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Sp...</td>\n",
       "      <td>209</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Gradient Aviator Sunglasses (57)</td>\n",
       "      <td>233</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>233</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product Brand                                Product Description  \\\n",
       "0           PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "1         Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "2         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "3           PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "4   kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "..             ...                                                ...   \n",
       "95       ROYAL SON                UV Protection Round Sunglasses (50)   \n",
       "96          PIRASO              UV Protection Aviator Sunglasses (50)   \n",
       "97           NuVew  UV Protection, Night Vision, Riding Glasses Sp...   \n",
       "98          GANSTA    UV Protection, Gradient Aviator Sunglasses (57)   \n",
       "99          GANSTA              UV Protection Aviator Sunglasses (57)   \n",
       "\n",
       "   Price of Product Discount on Product  \n",
       "0              237             85% off  \n",
       "1              541             32% off  \n",
       "2              537             32% off  \n",
       "3              237             85% off  \n",
       "4              299             88% off  \n",
       "..              ...                 ...  \n",
       "95             399             73% off  \n",
       "96             331             79% off  \n",
       "97             209             77% off  \n",
       "98             233             82% off  \n",
       "99             233             77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipkart_sunglasses('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iphone_100_review(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<10:\n",
    "    \n",
    "        ratings=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in ratings:\n",
    "            rating.append(i.text)\n",
    "        \n",
    "        reviews=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for i in reviews:\n",
    "            review_summary.append(i.text)\n",
    "        \n",
    "        full_reviews=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for i in full_reviews:\n",
    "            full_review.append(i.text)\n",
    "        time.sleep(10)    \n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        time.sleep(10)\n",
    "        j+=1\n",
    "        time.sleep(10)\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    iphone_review=pd.DataFrame({})\n",
    "    iphone_review['Rating']=rating\n",
    "    iphone_review['Review Summary']=review_summary\n",
    "    iphone_review['Full Reviews']=full_review\n",
    "    return iphone_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nIm am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Superb Product !!!\\nA big and worthy upgrade f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5       Great product   \n",
       "3       5   Worth every penny   \n",
       "4       5           Fabulous!   \n",
       "..    ...                 ...   \n",
       "95      5            Terrific   \n",
       "96      5      Classy product   \n",
       "97      5  Highly recommended   \n",
       "98      5           Wonderful   \n",
       "99      5           Brilliant   \n",
       "\n",
       "                                         Full Reviews  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nIm am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Really worth of money. i just love it. It is t...  \n",
       "96  Superb Product !!!\\nA big and worthy upgrade f...  \n",
       "97  It's my first time to use iOS phone and I am l...  \n",
       "98  This is my first ever I phone. Before this I w...  \n",
       "99  I have migrated from OP 7pro... and trust me, ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_100_review('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_sneakers(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Let's navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's search for sneaker product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    sneaker_brand_name=[]\n",
    "    sneaker_description=[]\n",
    "    sneaker_price=[]\n",
    "    sneaker_discount=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sneaker_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sneaker_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sneaker_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sneaker_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    # Let's create a DataFrame for our data   \n",
    "    sneakers_flipkart=pd.DataFrame({})\n",
    "    sneakers_flipkart['Brand Name']=sneaker_brand_name[:100]\n",
    "    sneakers_flipkart['Product Descriptions']=sneaker_description[:100]\n",
    "    sneakers_flipkart['Price']=sneaker_price[:100]\n",
    "    sneakers_flipkart['Discount %']=sneaker_discount[:100]\n",
    "    return sneakers_flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India hub</td>\n",
       "      <td>Fashionable casual sneakers shoes Sneakers For...</td>\n",
       "      <td>389</td>\n",
       "      <td>2610 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 4 Sneakers F...</td>\n",
       "      <td>748</td>\n",
       "      <td>1248 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shoes Bank</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>349</td>\n",
       "      <td>650 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>474</td>\n",
       "      <td>525 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORICUM</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>377</td>\n",
       "      <td>621 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Simha IDP Sneakers For Men</td>\n",
       "      <td>1,397</td>\n",
       "      <td>1602 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>359</td>\n",
       "      <td>2140 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>FILA</td>\n",
       "      <td>EMAN Sneakers For Men</td>\n",
       "      <td>1,333</td>\n",
       "      <td>1766 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>499</td>\n",
       "      <td>1497 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual for men Sneakers For Men</td>\n",
       "      <td>474</td>\n",
       "      <td>525 off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand Name                               Product Descriptions   Price  \\\n",
       "0      India hub  Fashionable casual sneakers shoes Sneakers For...    389   \n",
       "1       CALCADOS  Modern Trendy Shoes Combo pack of 4 Sneakers F...    748   \n",
       "2     Shoes Bank     White Sneaker For Men's/Boy's Sneakers For Men    349   \n",
       "3   Robbie jones                                   Sneakers For Men    474   \n",
       "4         ORICUM  Combo pack of 2 casual sneaker shoes for men S...    377   \n",
       "..           ...                                                ...     ...   \n",
       "95          PUMA                         Simha IDP Sneakers For Men  1,397   \n",
       "96        BRUTON      Combo Pack of 2 Casual Shoes Sneakers For Men    359   \n",
       "97          FILA                              EMAN Sneakers For Men  1,333   \n",
       "98        Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...    499   \n",
       "99     bluemaker                    casual for men Sneakers For Men    474   \n",
       "\n",
       "   Discount %  \n",
       "0   2610 off  \n",
       "1   1248 off  \n",
       "2    650 off  \n",
       "3    525 off  \n",
       "4    621 off  \n",
       "..        ...  \n",
       "95  1602 off  \n",
       "96  2140 off  \n",
       "97  1766 off  \n",
       "98  1497 off  \n",
       "99   525 off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_sneakers('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shoes_myntra(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    brand_name=[]\n",
    "    description=[]\n",
    "    product_price=[]\n",
    "    \n",
    "    #Let's apply filter for price\n",
    "    driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's apply filter for colour\n",
    "    driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<2:\n",
    "        time.sleep(5)\n",
    "        \n",
    "        brands=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "        for q in brands:\n",
    "            brand_name.append(q.text)\n",
    "        \n",
    "        descs=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "        for q in descs:\n",
    "            description.append(q.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "        for q in prices:\n",
    "            product_price.append(q.text)\n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@rel=\"next\"]').click()    \n",
    "        time.sleep(5)\n",
    "        j+=1\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    myntra_shoes=pd.DataFrame({})\n",
    "    myntra_shoes['Brand of the Shoes']=brand_name[0:100]\n",
    "    myntra_shoes['Short Shoes Description']=description[0:100]\n",
    "    myntra_shoes['Price of the Shoes']=product_price[0:100]\n",
    "    return myntra_shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand of the Shoes</th>\n",
       "      <th>Short Shoes Description</th>\n",
       "      <th>Price of the Shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM FREAK 2 Basketball</td>\n",
       "      <td>Rs. 7721Rs. 10295(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Solid Leather Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex COSMIC UNITY Basketball</td>\n",
       "      <td>Rs. 11470Rs. 13495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO RUN 7+ Running Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RAPAWALK</td>\n",
       "      <td>Wide Width Leather Oxfords</td>\n",
       "      <td>Rs. 8850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Peep Toe Heels</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Sneakers Casual Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Formal Leather Brogues</td>\n",
       "      <td>Rs. 7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "      <td>Rs. 7699Rs. 10999(30% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand of the Shoes         Short Shoes Description  \\\n",
       "0                   Nike     Men ZOOM FREAK 2 Basketball   \n",
       "1         Tommy Hilfiger      Men Solid Leather Sneakers   \n",
       "2                   Nike  Unisex COSMIC UNITY Basketball   \n",
       "3               Skechers     Men GO RUN 7+ Running Shoes   \n",
       "4                   Nike     Men JORDAN DELTA Basketball   \n",
       "..                   ...                             ...   \n",
       "95              RAPAWALK      Wide Width Leather Oxfords   \n",
       "96  Heel & Buckle London            Women Peep Toe Heels   \n",
       "97                  FILA     Women Sneakers Casual Shoes   \n",
       "98                 Ruosh      Men Formal Leather Brogues   \n",
       "99             Cole Haan          Women Leather Sneakers   \n",
       "\n",
       "             Price of the Shoes  \n",
       "0    Rs. 7721Rs. 10295(25% OFF)  \n",
       "1                      Rs. 7999  \n",
       "2   Rs. 11470Rs. 13495(15% OFF)  \n",
       "3                      Rs. 9999  \n",
       "4                     Rs. 12495  \n",
       "..                          ...  \n",
       "95                     Rs. 8850  \n",
       "96    Rs. 7192Rs. 8990(20% OFF)  \n",
       "97                     Rs. 7999  \n",
       "98                     Rs. 7490  \n",
       "99   Rs. 7699Rs. 10999(30% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes_myntra('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Let's search for laptop product and then click search button\n",
    "driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "driver.find_element_by_xpath('//input[@type=\"submit\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's apply filter for \"Intel Core i7\"\n",
    "driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a',).click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's apply filter for \"Intel Core i9\"  \n",
    "driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Let's create empty list for storing the data\n",
    "item_title=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scrape the data\n",
    "titles=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in titles:\n",
    "    item_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create empty list for storing the data\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scrape the data\n",
    "prices=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for i in prices:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create empty list for storing the data\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scrape the data\n",
    "ratings=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')   \n",
    "for i in ratings:\n",
    "    rating.append(i.get_attribute('aria-label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a DataFrame for our data\n",
    "amazon_laptops=pd.DataFrame({})\n",
    "amazon_laptops['Title']=item_title[:10]\n",
    "amazon_laptops['Price']=price[:10]\n",
    "amazon_laptops['Rating']=rating[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...</td>\n",
       "      <td>83,990</td>\n",
       "      <td>3.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>97,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>54,999</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>26,990</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>89,000</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>2,69,990</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" 4K UHD, Intel ...</td>\n",
       "      <td>86,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>97,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>51,999</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price  \\\n",
       "0  Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...    83,990   \n",
       "1  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...    97,990   \n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i5-1...    54,999   \n",
       "3  Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...    84,990   \n",
       "4  HP Pavilion (2021) Thin & Light 11th Gen Core ...    26,990   \n",
       "5  Life Digital Laptop 15.6-inch (39.62 cms) (Int...    89,000   \n",
       "6  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...  2,69,990   \n",
       "7  ASUS ROG Zephyrus Duo 15, 15.6\" 4K UHD, Intel ...    86,990   \n",
       "8  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    97,990   \n",
       "9  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...    51,999   \n",
       "\n",
       "               Rating  \n",
       "0  3.2 out of 5 stars  \n",
       "1  4.2 out of 5 stars  \n",
       "2  4.4 out of 5 stars  \n",
       "3  4.5 out of 5 stars  \n",
       "4  3.1 out of 5 stars  \n",
       "5  4.7 out of 5 stars  \n",
       "6  3.8 out of 5 stars  \n",
       "7  4.1 out of 5 stars  \n",
       "8  4.2 out of 5 stars  \n",
       "9  4.4 out of 5 stars  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_laptops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
