{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#Importing requests\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to the wed driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\karishma yadav\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Opening the homepage of wikipedia.com\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "\n",
    "# Extracting name from xpath\n",
    "name=driver.find_elements_by_xpath('//a[@class=\"mw-redirect\"]')   \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text) \n",
    "    \n",
    "# Extracting upload date from xpath\n",
    "upload_date=driver.find_elements_by_xpath('//td[@align=\"right\"]')  \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Upload_date=[]\n",
    "for j in upload_date:\n",
    "    Upload_date.append(j.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank from xpath\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '8.96',\n",
       " '[B]',\n",
       " '2.',\n",
       " '7.44',\n",
       " '[C]',\n",
       " '3.',\n",
       " '5.55',\n",
       " '[D]',\n",
       " '4.',\n",
       " '5.38',\n",
       " '[E]',\n",
       " '5.',\n",
       " '5.18',\n",
       " '[F]',\n",
       " '6.',\n",
       " '4.44',\n",
       " '[G]',\n",
       " '7.',\n",
       " '4.31',\n",
       " '[H]',\n",
       " '8.',\n",
       " '4.26',\n",
       " '[I]',\n",
       " '9.',\n",
       " '4.23',\n",
       " '[J]',\n",
       " '10.',\n",
       " '4.12',\n",
       " '[K]',\n",
       " '11.',\n",
       " '3.99',\n",
       " '12.',\n",
       " '3.51',\n",
       " '13.',\n",
       " '3.46',\n",
       " '14.',\n",
       " '3.45',\n",
       " '15.',\n",
       " '3.39',\n",
       " '16.',\n",
       " '3.34',\n",
       " '17.',\n",
       " '3.29',\n",
       " '18.',\n",
       " '3.15',\n",
       " '19.',\n",
       " '3.10',\n",
       " '20.',\n",
       " '3.10',\n",
       " '21.',\n",
       " '3.07',\n",
       " '22.',\n",
       " '3.07',\n",
       " '23.',\n",
       " '3.06',\n",
       " '24.',\n",
       " '3.06',\n",
       " '25.',\n",
       " '3.03',\n",
       " '26.',\n",
       " '2.94',\n",
       " '27.',\n",
       " '2.90',\n",
       " '28.',\n",
       " '2.88',\n",
       " '29.',\n",
       " '2.88',\n",
       " '30.',\n",
       " '2.85',\n",
       " '',\n",
       " '',\n",
       " '[118]',\n",
       " '[O]',\n",
       " '[28]',\n",
       " '[35]',\n",
       " '[P]',\n",
       " '[119]',\n",
       " '[Q]',\n",
       " '93',\n",
       " '[122]',\n",
       " '[R]',\n",
       " '171',\n",
       " '[125]',\n",
       " '176',\n",
       " '[126]',\n",
       " '289',\n",
       " '[129]',\n",
       " '124',\n",
       " '[130]',\n",
       " '14',\n",
       " '[132]',\n",
       " '[S]',\n",
       " '[135]',\n",
       " '[T]',\n",
       " '68',\n",
       " '[137]',\n",
       " '[U]',\n",
       " '22',\n",
       " '[142]',\n",
       " '28',\n",
       " '[144]',\n",
       " '[V]',\n",
       " '12',\n",
       " '[146]',\n",
       " '[148]',\n",
       " '[W]',\n",
       " '[151]',\n",
       " '[152]']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Rak=[]\n",
    "for i in rank:\n",
    "    Rak.append(i.text)    \n",
    "Rak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.']\n",
      "['2.']\n",
      "['3.']\n",
      "['4.']\n",
      "['5.']\n",
      "['6.']\n",
      "['7.']\n",
      "['8.']\n",
      "['9.']\n",
      "['10.']\n",
      "['11.']\n",
      "['13.']\n",
      "['14.']\n",
      "['15.']\n",
      "['16.']\n",
      "['17.']\n",
      "['18.']\n",
      "['19.']\n",
      "['20.']\n"
     ]
    }
   ],
   "source": [
    "Rank1=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank1.append(j.text)    \n",
    "print(Rank1[0:1])\n",
    "\n",
    "Rank2=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank2.append(j.text)    \n",
    "print(Rank2[3:4])\n",
    "\n",
    "Rank3=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank3.append(j.text)    \n",
    "print(Rank3[6:7])\n",
    "\n",
    "Rank4=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank4.append(j.text)    \n",
    "print(Rank4[9:10])\n",
    "\n",
    "Rank5=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank5.append(j.text)    \n",
    "print(Rank5[12:13])\n",
    "\n",
    "Rank6=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank6.append(j.text)    \n",
    "print(Rank6[15:16])\n",
    "\n",
    "Rank7=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank7.append(j.text)    \n",
    "print(Rank7[18:19])\n",
    "\n",
    "Rank8=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank8.append(j.text)    \n",
    "print(Rank8[21:22])\n",
    "\n",
    "Rank9=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank9.append(j.text)    \n",
    "print(Rank9[24:25])\n",
    "\n",
    "Rank10=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank10.append(j.text)    \n",
    "print(Rank10[27:28])\n",
    "\n",
    "Rank11=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank11.append(j.text)    \n",
    "print(Rank11[30:31])\n",
    "\n",
    "Rank12=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank12.append(j.text)    \n",
    "print(Rank12[34:35])\n",
    "\n",
    "Rank13=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank13.append(j.text)    \n",
    "print(Rank13[36:37])\n",
    "\n",
    "Rank14=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank14.append(j.text)    \n",
    "print(Rank14[38:39])\n",
    "\n",
    "Rank15=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank15.append(j.text)    \n",
    "print(Rank15[40:41])\n",
    "\n",
    "Rank16=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank16.append(j.text)    \n",
    "print(Rank16[42:43])\n",
    "\n",
    "Rank17=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank17.append(j.text)    \n",
    "print(Rank17[44:45])\n",
    "\n",
    "Rank18=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank18.append(j.text)    \n",
    "print(Rank18[46:47])\n",
    "\n",
    "Rank19=[]\n",
    "rank=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in rank:\n",
    "    Rank19.append(j.text)    \n",
    "print(Rank19[48:49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8.96']\n",
      "['7.44']\n",
      "['5.55']\n",
      "['5.38']\n",
      "['5.18']\n",
      "['4.44']\n",
      "['4.31']\n",
      "['4.26']\n",
      "['4.23']\n",
      "['4.12']\n",
      "['3.99']\n",
      "['3.51']\n",
      "['3.46']\n",
      "['3.45']\n",
      "['3.39']\n",
      "['3.29']\n",
      "['3.15']\n",
      "['3.10']\n",
      "['3.10']\n",
      "['3.07']\n",
      "['3.07']\n"
     ]
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View.append(j.text)    \n",
    "print(View[1:2])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View1=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View1.append(j.text)    \n",
    "print(View1[4:5])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View2=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View2.append(j.text)    \n",
    "print(View2[7:8])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View3=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View3.append(j.text)    \n",
    "print(View3[10:11])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View4=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View4.append(j.text)    \n",
    "print(View4[13:14])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View5=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View5.append(j.text)    \n",
    "print(View5[16:17])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View6=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View6.append(j.text)    \n",
    "print(View6[19:20])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View7=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View7.append(j.text)    \n",
    "print(View7[22:23])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View8=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View8.append(j.text)    \n",
    "print(View8[25:26])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View9=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View9.append(j.text)    \n",
    "print(View9[28:29])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View10=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View10.append(j.text)    \n",
    "print(View10[31:32])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View11=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View11.append(j.text)    \n",
    "print(View11[33:34])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View12=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View12.append(j.text)    \n",
    "print(View12[35:36])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View13=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View13.append(j.text)    \n",
    "print(View13[37:38])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View14=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View14.append(j.text)    \n",
    "print(View14[39:40])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View15=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View15.append(j.text)    \n",
    "print(View15[43:44])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View16=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View16.append(j.text)    \n",
    "print(View16[45:46])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View17=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View17.append(j.text)    \n",
    "print(View17[47:48])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View18=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View18.append(j.text)    \n",
    "print(View18[49:50])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View19=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View19.append(j.text)    \n",
    "print(View19[51:52])\n",
    "\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "View20=[]\n",
    "# Extracting Views from xpath\n",
    "view=driver.find_elements_by_xpath('//td[@align=\"center\"]')   \n",
    "for j in view:\n",
    "    View20.append(j.text)    \n",
    "print(View20[53:54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.96,\n",
       " 7.44,\n",
       " 5.55,\n",
       " 5.38,\n",
       " 5.18,\n",
       " 4.44,\n",
       " 4.31,\n",
       " 4.26,\n",
       " 4.23,\n",
       " 4.12,\n",
       " 3.99,\n",
       " 3.51,\n",
       " 3.46,\n",
       " 3.45,\n",
       " 3.39,\n",
       " 3.29,\n",
       " 3.15,\n",
       " 3.1,\n",
       " 3.1,\n",
       " 3.07,\n",
       " 3.07]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Views=[8.96,7.44,5.55,5.38,5.18,4.44,4.31,4.26,4.23,4.12,3.99,3.51,3.46,3.45,3.39,3.29,3.15,3.10,3.10,3.07,3.07]\n",
    "Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting artist from xpath\n",
    "artist=driver.find_elements_by_xpath('//a[@title=\"Pinkfong\"]')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pinkfong', \"Pinkfong Kids' Songs & Stories\", 'Pinkfong', 'Pinkfong']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Artist=[]\n",
    "for j in artist:\n",
    "    Artist.append(j.text)    \n",
    "Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a DataFrame\n",
    "a={\"Rank\":Rank,     \"Name\": Name,     \"Views\": Views,     \"Upload Date\": Upload_date}\n",
    "YouTube=pd.DataFrame.from_dict(a, orient='index')\n",
    "YouTube=YouTube.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>music videos</td>\n",
       "      <td>8.96</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>7.44</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>5.55</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>5.38</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.18</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.44</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.31</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Gummy Bear Song</td>\n",
       "      <td>4.26</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Fueled By Ramen</td>\n",
       "      <td>4.23</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Gummy Bear Song</td>\n",
       "      <td>4.12</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Osito Gominola – Full Spanish Version – The Gu...</td>\n",
       "      <td>3.99</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>3.51</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Closer</td>\n",
       "      <td>3.46</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.45</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.39</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>3.29</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>List of most-viewed online trailers in the fir...</td>\n",
       "      <td>3.15</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>regional restrictions</td>\n",
       "      <td>3.1</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>regional restrictions</td>\n",
       "      <td>3.1</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Wired</td>\n",
       "      <td>3.07</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>3.07</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                               Name Views  \\\n",
       "0      1                                       music videos  8.96   \n",
       "1      2                                   Baby Shark Dance  7.44   \n",
       "2      3                                   Baby Shark Dance  5.55   \n",
       "3      4                                   Baby Shark Dance  5.38   \n",
       "4      5                         Cocomelon – Nursery Rhymes  5.18   \n",
       "5      6                         Cocomelon – Nursery Rhymes  4.44   \n",
       "6      7                         Cocomelon – Nursery Rhymes  4.31   \n",
       "7      8                                The Gummy Bear Song  4.26   \n",
       "8      9                                    Fueled By Ramen  4.23   \n",
       "9     10                                The Gummy Bear Song  4.12   \n",
       "10    11  Osito Gominola – Full Spanish Version – The Gu...  3.99   \n",
       "11    12                                   Baby Shark Dance  3.51   \n",
       "12    13                                             Closer  3.46   \n",
       "13    14                         Cocomelon – Nursery Rhymes  3.45   \n",
       "14    15                         Cocomelon – Nursery Rhymes  3.39   \n",
       "15    16                                   Baby Shark Dance  3.29   \n",
       "16    17  List of most-viewed online trailers in the fir...  3.15   \n",
       "17    18                              regional restrictions   3.1   \n",
       "18    19                              regional restrictions   3.1   \n",
       "19    20                                              Wired  3.07   \n",
       "20  None                                                     3.07   \n",
       "\n",
       "          Upload Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3    January 30, 2017  \n",
       "4       April 6, 2015  \n",
       "5    January 31, 2012  \n",
       "6         May 2, 2018  \n",
       "7   February 27, 2018  \n",
       "8   November 19, 2014  \n",
       "9       July 15, 2012  \n",
       "10      March 6, 2014  \n",
       "11   January 14, 2015  \n",
       "12      April 5, 2018  \n",
       "13   October 22, 2015  \n",
       "14  September 5, 2013  \n",
       "15       May 31, 2013  \n",
       "16    October 7, 2014  \n",
       "17       May 24, 2018  \n",
       "18  February 20, 2014  \n",
       "19   December 3, 2015  \n",
       "20    August 18, 2014  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTube[:21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of bcci.tv\n",
    "url='https://www.bcci.tv/'\n",
    "driver.get(url)\n",
    "\n",
    "# extract all the tags having the match_title\n",
    "Match_Title=[]\n",
    "match_title=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']\")\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for i in match_title:\n",
    "    Match_Title.append(i.text)\n",
    "    \n",
    "# extract all the tags having the date    \n",
    "Date=[]\n",
    "date=driver.find_elements_by_xpath(\"//span[@class='fixture__date']\") \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for i in date:\n",
    "    Date.append(i.text) \n",
    "    \n",
    "    \n",
    "# extract all the tags having the place\n",
    "Place=[]\n",
    "place=driver.find_elements_by_xpath(\"//div[@class='fixture__info u-skewed']\")\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for i in place:\n",
    "    Place.append(i.text) \n",
    "    \n",
    "    \n",
    "# extract all the tags having the series\n",
    "Series=[]\n",
    "series=driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for j in series:\n",
    "    Series.append(j.text)  \n",
    "    \n",
    "Time=[]\n",
    "time=driver.find_elements_by_xpath(\"//div[@class='fixture__full-date']\")\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for j in time:\n",
    "    Time.append(j.text)    \n",
    "\n",
    "# make a dataframe    \n",
    "India_Match=pd.DataFrame({})\n",
    "India_Match['Match_Title']=Match_Title\n",
    "India_Match['Time']=Time\n",
    "India_Match['Series']=Series\n",
    "India_Match['Place']=Place\n",
    "India_Match['Date']=Date   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Time</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2nd ODI Maharashtra Cricket Association Stadiu...</td>\n",
       "      <td></td>\n",
       "      <td>INDIA V ENGLAND 2021</td>\n",
       "      <td>ODI\\nINDIA V ENGLAND 2021\\nFriday 26 March\\n2n...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3rd ODI Maharashtra Cricket Association Stadiu...</td>\n",
       "      <td></td>\n",
       "      <td>INDIA V ENGLAND 2021</td>\n",
       "      <td>ODI\\nINDIA V ENGLAND 2021\\nSunday 28 March\\n3r...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only Test Bristol County Ground, Bristol</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>TEST\\nWednesday 16 June\\nOnly Test Bristol Cou...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Match_Title Time  \\\n",
       "0  2nd ODI Maharashtra Cricket Association Stadiu...        \n",
       "1  3rd ODI Maharashtra Cricket Association Stadiu...        \n",
       "2           Only Test Bristol County Ground, Bristol        \n",
       "3                                                           \n",
       "4                                                           \n",
       "5                                                           \n",
       "6                                                           \n",
       "7                                                           \n",
       "8                                                           \n",
       "9                                                           \n",
       "\n",
       "                 Series                                              Place  \\\n",
       "0  INDIA V ENGLAND 2021  ODI\\nINDIA V ENGLAND 2021\\nFriday 26 March\\n2n...   \n",
       "1  INDIA V ENGLAND 2021  ODI\\nINDIA V ENGLAND 2021\\nSunday 28 March\\n3r...   \n",
       "2                        TEST\\nWednesday 16 June\\nOnly Test Bristol Cou...   \n",
       "3                                                                            \n",
       "4                                                                            \n",
       "5                                                                            \n",
       "6                                                                            \n",
       "7                                                                            \n",
       "8                                                                            \n",
       "9                                                                            \n",
       "\n",
       "  Date  \n",
       "0       \n",
       "1       \n",
       "2       \n",
       "3       \n",
       "4       \n",
       "5       \n",
       "6       \n",
       "7       \n",
       "8       \n",
       "9       "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "India_Match[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Opening the homepage of guru99.com\n",
    "url= 'https://www.guru99.com/exception-handling-selenium.html'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Name=[]\n",
    "name=driver.find_elements_by_xpath(\"//table[@class='table table-striped']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Exception name Description\\nElementNotVisibleException This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.\\nElementNotSelectableException This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.\\nNoSuchElementException This Exception occurs if an element could not be found.\\nNoSuchFrameException This Exception occurs if the frame target to be switched to does not exist.\\nNoAlertPresentException This Exception occurs when you switch to no presented alert.\\nNoSuchWindowException This Exception occurs if the window target to be switch does not exist.\\nStaleElementReferenceException This Selenium exception occurs happens when the web element is detached from the current DOM.\\nSessionNotFoundException The WebDriver is acting after you quit the browser.\\nTimeoutException Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn't found in the specified time.\\nWebDriverException This Exception takes place when the WebDriver is acting right after you close the browser.\\nConnectionClosedException This type of Exception takes place when there is a disconnection in the driver.\\nElementClickInterceptedException The command may not be completed as the element receiving the events is concealing the element which was requested clicked.\\nElementNotInteractableException This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.\\nErrorInResponseException This happens while interacting with the Firefox extension or the remote driver server.\\nErrorHandler.UnknownServerException Exception is used as a placeholder in case if the server returns an error without a stack trace.\\nImeActivationFailedException This expectation will occur when IME engine activation has failed.\\nImeNotAvailableException It takes place when IME support is unavailable.\\nInsecureCertificateException Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.\\nInvalidArgumentException It occurs when an argument does not belong to the expected type.\\nInvalidCookieDomainException This happens when you try to add a cookie under a different domain instead of current URL.\\nInvalidCoordinatesException This type of Exception matches an interacting operation that is not valid.\\nInvalidElementStateExceptio It occurs when command can't be finished when the element is invalid.\\nInvalidSessionIdException This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.\\nInvalidSwitchToTargetException This occurs when the frame or window target to be switched does not exist.\\nJavascriptException This issue occurs while executing JavaScript given by the user.\\nJsonException It occurs when you afford to get the session when the session is not created.\\nNoSuchAttributeException This kind of Exception occurs when the attribute of an element could not be found.\\nMoveTargetOutOfBoundsException It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.\\nNoSuchContextException ContextAware does mobile device testing.\\nNoSuchCookieException This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.\\nNotFoundException This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.\\nRemoteDriverServerException This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.\\nScreenshotException It is not possible to capture a screen.\\nSessionNotCreatedException It happens when a new session could not be successfully created.\\nUnableToSetCookieException This occurs if a driver is unable to set a cookie.\\nUnexpectedTagNameException Happens if a support class did not get a web element as expected.\\nUnhandledAlertException This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.\\nUnexpectedAlertPresentException It occurs when there is the appearance of an unexpected alert.\\nUnknownMethodException This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.\\nUnreachableBrowserException This Exception occurs only when the browser is not able to be opened or crashed because of some reason.\\nUnsupportedCommandException This occurs when remote WebDriver does n't send valid commands as expected.\"]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for j in name:\n",
    "    Name.append(j.text)    \n",
    "Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Opening the homepage of statisticstimes.com\n",
    "url= 'https://statisticstimes.com/economy/india/indian-states-gdp.php'\n",
    "driver.get(url)\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "rank=driver.find_elements_by_xpath('//td[@class=\"data1\"]')   \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Rank=[]\n",
    "for i in rank:\n",
    "    Rank.append(i.text)    \n",
    "\n",
    "# Extracting state from xpath\n",
    "state=driver.find_elements_by_xpath('//td[@class=\"name\"]')   \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "State=[]\n",
    "for i in state:\n",
    "    State.append(i.text)  \n",
    "    \n",
    "# Extracting current price from xpath\n",
    "gsdp_current_price=driver.find_elements_by_xpath('//td[@class=\"data\"]')   \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "GSDP_current_price=[]\n",
    "for i in gsdp_current_price:\n",
    "    GSDP_current_price.append(i.text)    \n",
    "    \n",
    "# Extracting current price from xpath\n",
    "gsdp_c_p=driver.find_elements_by_xpath('//td[@class=\"data sorting_1\"]')  \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "GSDP_c_p=[]\n",
    "for i in gsdp_c_p:\n",
    "    GSDP_c_p.append(i.text) \n",
    "    \n",
    "# Extracting share from xpath\n",
    "share=driver.find_elements_by_xpath('//td[@class=\"data\"]')  \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Share=[]\n",
    "for i in share:\n",
    "    Share.append(i.text)  \n",
    "    \n",
    "# Extracting gdp from xpath\n",
    "gdp=driver.find_elements_by_xpath('//td[@class=\"data\"]')   \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "GDP=[]\n",
    "for i in gdp:\n",
    "    GDP.append(i.text)  \n",
    "    \n",
    "# make a DataFrame\n",
    "a={\"Rank\": Rank,\"State\": State,\"GSDP current price(19-20)\": GSDP_current_price,\"GSDP current price(18-19)\":GSDP_c_p,\"Share(18-19)\": Share,\"GDP($billion)\":GDP}\n",
    "GDP=pd.DataFrame.from_dict(a, orient='index')\n",
    "GDP=GDP.transpose()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP current price(19-20)</th>\n",
       "      <th>GSDP current price(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>13.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>399.921</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>399.921</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>2,039,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,845,853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>942,586</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>8.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>247.629</td>\n",
       "      <td>862,957</td>\n",
       "      <td>247.629</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>861,031</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>1,312,929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>809,592</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>1,215,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>781,653</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,687,818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>774,870</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>8.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>240.726</td>\n",
       "      <td>734,163</td>\n",
       "      <td>240.726</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>530,363</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>1,166,817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>1,123,982</td>\n",
       "      <td>526,376</td>\n",
       "      <td>1,123,982</td>\n",
       "      <td>1,123,982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>-</td>\n",
       "      <td>487,805</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>315,881</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>7.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>228.290</td>\n",
       "      <td>304,063</td>\n",
       "      <td>228.290</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>-</td>\n",
       "      <td>297,204</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>1,186,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>155,956</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,631,977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>153,845</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>7.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>226.806</td>\n",
       "      <td>73,170</td>\n",
       "      <td>226.806</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>49,845</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>1,156,039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>1,091,077</td>\n",
       "      <td>42,114</td>\n",
       "      <td>1,091,077</td>\n",
       "      <td>1,091,077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>34,433</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,253,832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>33,481</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>5.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>165.556</td>\n",
       "      <td>28,723</td>\n",
       "      <td>165.556</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>793,223</td>\n",
       "      <td>27,870</td>\n",
       "      <td>793,223</td>\n",
       "      <td>793,223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>739,525</td>\n",
       "      <td>27,283</td>\n",
       "      <td>739,525</td>\n",
       "      <td>739,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>24,603</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>1,020,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>22,287</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>4.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>143.179</td>\n",
       "      <td>-</td>\n",
       "      <td>143.179</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>India</td>\n",
       "      <td>711,627</td>\n",
       "      <td>2,332,992</td>\n",
       "      <td>711,627</td>\n",
       "      <td>711,627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP current price(19-20)  \\\n",
       "0     1                Maharashtra                         -   \n",
       "1     2                 Tamil Nadu                    13.94%   \n",
       "2     3              Uttar Pradesh                   399.921   \n",
       "3     4                    Gujarat                         -   \n",
       "4     5                  Karnataka                 2,039,074   \n",
       "5     6                West Bengal                 1,845,853   \n",
       "6     7                  Rajasthan                     8.63%   \n",
       "7     8             Andhra Pradesh                   247.629   \n",
       "8     9                  Telangana                 1,312,929   \n",
       "9    10             Madhya Pradesh                 1,215,307   \n",
       "10   11                     Kerala                 1,687,818   \n",
       "11   12                      Delhi                     8.39%   \n",
       "12   13                    Haryana                   240.726   \n",
       "13   14                      Bihar                 1,166,817   \n",
       "14   15                     Punjab                 1,123,982   \n",
       "15   16                     Odisha                         -   \n",
       "16   17                      Assam                     7.96%   \n",
       "17   18               Chhattisgarh                   228.290   \n",
       "18   19                  Jharkhand                         -   \n",
       "19   20                Uttarakhand                 1,186,379   \n",
       "20   21            Jammu & Kashmir                 1,631,977   \n",
       "21   22           Himachal Pradesh                     7.91%   \n",
       "22   23                        Goa                   226.806   \n",
       "23   24                    Tripura                 1,156,039   \n",
       "24   25                 Chandigarh                 1,091,077   \n",
       "25   26                 Puducherry                 1,253,832   \n",
       "26   27                  Meghalaya                     5.77%   \n",
       "27   28                     Sikkim                   165.556   \n",
       "28   29                    Manipur                   793,223   \n",
       "29   30                   Nagaland                   739,525   \n",
       "30   31          Arunachal Pradesh                 1,020,989   \n",
       "31   32                    Mizoram                     4.99%   \n",
       "32   33  Andaman & Nicobar Islands                   143.179   \n",
       "33                           India                   711,627   \n",
       "\n",
       "   GSDP current price(18-19) Share(18-19) GDP($billion)  \n",
       "0                  2,632,792            -             -  \n",
       "1                  1,630,208       13.94%        13.94%  \n",
       "2                  1,584,764      399.921       399.921  \n",
       "3                  1,502,899            -             -  \n",
       "4                  1,493,127    2,039,074     2,039,074  \n",
       "5                  1,089,898    1,845,853     1,845,853  \n",
       "6                    942,586        8.63%         8.63%  \n",
       "7                    862,957      247.629       247.629  \n",
       "8                    861,031    1,312,929     1,312,929  \n",
       "9                    809,592    1,215,307     1,215,307  \n",
       "10                   781,653    1,687,818     1,687,818  \n",
       "11                   774,870        8.39%         8.39%  \n",
       "12                   734,163      240.726       240.726  \n",
       "13                   530,363    1,166,817     1,166,817  \n",
       "14                   526,376    1,123,982     1,123,982  \n",
       "15                   487,805            -             -  \n",
       "16                   315,881        7.96%         7.96%  \n",
       "17                   304,063      228.290       228.290  \n",
       "18                   297,204            -             -  \n",
       "19                   245,895    1,186,379     1,186,379  \n",
       "20                   155,956    1,631,977     1,631,977  \n",
       "21                   153,845        7.91%         7.91%  \n",
       "22                    73,170      226.806       226.806  \n",
       "23                    49,845    1,156,039     1,156,039  \n",
       "24                    42,114    1,091,077     1,091,077  \n",
       "25                    34,433    1,253,832     1,253,832  \n",
       "26                    33,481        5.77%         5.77%  \n",
       "27                    28,723      165.556       165.556  \n",
       "28                    27,870      793,223       793,223  \n",
       "29                    27,283      739,525       739,525  \n",
       "30                    24,603    1,020,989     1,020,989  \n",
       "31                    22,287        4.99%         4.99%  \n",
       "32                         -      143.179       143.179  \n",
       "33                 2,332,992      711,627       711,627  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP[:34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of github.com\n",
    "url= 'https://github.com/trending'\n",
    "driver.get(url)\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "title=driver.find_elements_by_xpath('//article[@class=\"Box-row\"]/h1') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title=[]\n",
    "for j in title:\n",
    "    Title.append(j.text)    \n",
    "\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "description=driver.find_elements_by_xpath('//p[@class=\"col-9 color-text-secondary my-1 pr-4\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Description=[]\n",
    "for j in description:\n",
    "    Description.append(j.text)    \n",
    "\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "language=driver.find_elements_by_xpath('//span[@class=\"d-inline-block ml-0 mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Language=[]\n",
    "for j in language:\n",
    "    Language.append(j.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,780',\n",
       " '123',\n",
       " '18,642',\n",
       " '4,144',\n",
       " '3,748',\n",
       " '297',\n",
       " '27,675',\n",
       " '3,618',\n",
       " '713',\n",
       " '89',\n",
       " '2,813',\n",
       " '254',\n",
       " '65,943',\n",
       " '8,659',\n",
       " '2,286',\n",
       " '225',\n",
       " '4,224',\n",
       " '783',\n",
       " '344',\n",
       " '25',\n",
       " '528',\n",
       " '80',\n",
       " '11,634',\n",
       " '2,660',\n",
       " '7,876',\n",
       " '1,134',\n",
       " '1,819',\n",
       " '442',\n",
       " '130',\n",
       " '34',\n",
       " '43,795',\n",
       " '4,834',\n",
       " '35,836',\n",
       " '5,141',\n",
       " '6,786',\n",
       " '2,860',\n",
       " '13,670',\n",
       " '2,808',\n",
       " '28,199',\n",
       " '720',\n",
       " '80',\n",
       " '44',\n",
       " '3,350',\n",
       " '567',\n",
       " '1,937',\n",
       " '152',\n",
       " '144',\n",
       " '86',\n",
       " '6,908',\n",
       " '961']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count.append(j.text)    \n",
    "Contributors_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['124']\n",
      "['298']\n",
      "['254']\n",
      "['225']\n",
      "['783']\n",
      "['346']\n",
      "['25']\n",
      "['529']\n",
      "['81']\n",
      "['131']\n",
      "['35']\n",
      "['82']\n",
      "['35']\n",
      "['44']\n",
      "['567']\n",
      "['152']\n",
      "['144']\n"
     ]
    }
   ],
   "source": [
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count1=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count1.append(j.text)    \n",
    "print(Contributors_count1[1:2])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count2=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count2.append(j.text)    \n",
    "print(Contributors_count2[5:6])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count3=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count3.append(j.text)    \n",
    "print(Contributors_count3[11:12])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count4=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count4.append(j.text)    \n",
    "print(Contributors_count4[15:16])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count5=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count5.append(j.text)    \n",
    "print(Contributors_count5[17:18])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count6=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count6.append(j.text)    \n",
    "print(Contributors_count6[18:19])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count7=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count7.append(j.text)    \n",
    "print(Contributors_count7[19:20])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count8=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count8.append(j.text)    \n",
    "print(Contributors_count8[20:21])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count9=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count9.append(j.text)    \n",
    "print(Contributors_count9[21:22])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count1=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count1.append(j.text)    \n",
    "print(Contributors_count1[28:29])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count10=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count10.append(j.text)    \n",
    "print(Contributors_count10[29:30])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count11=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count11.append(j.text)    \n",
    "print(Contributors_count11[40:41])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count12=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count12.append(j.text)    \n",
    "print(Contributors_count12[29:30])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count13=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count13.append(j.text)    \n",
    "print(Contributors_count13[41:42])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count14=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count14.append(j.text)    \n",
    "print(Contributors_count14[43:44])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count15=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count15.append(j.text)    \n",
    "print(Contributors_count15[45:46])\n",
    "\n",
    "# Extracting Rank from xpath\n",
    "contributors_count=driver.find_elements_by_xpath('//a[@class=\"Link--muted d-inline-block mr-3\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Contributors_count16=[]\n",
    "for j in contributors_count:\n",
    "    Contributors_count16.append(j.text)    \n",
    "print(Contributors_count16[46:47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124,\n",
       " 298,\n",
       " 713,\n",
       " 89,\n",
       " 225,\n",
       " 783,\n",
       " 346,\n",
       " 25,\n",
       " 529,\n",
       " 81,\n",
       " 131,\n",
       " 35,\n",
       " 82,\n",
       " 82,\n",
       " 44,\n",
       " 567,\n",
       " 152,\n",
       " 144]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contributors_Count=[124,298,713,89,225,783,346,25,529,81,131,35,82,82,44,567,152,144]\n",
    "Contributors_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a DataFrame\n",
    "a={\"Repository title\": Title, \"Repository description\": Description, \"Contributors count\": Contributors_Count, \"Language used\": Language}\n",
    "Github=pd.DataFrame.from_dict(a,orient='index')\n",
    "Github=Github.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bndw / wifi-card</td>\n",
       "      <td>📶 Print a QR code for connecting to your WiFi</td>\n",
       "      <td>124</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook / folly</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>298</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft / IoT-For-Beginners</td>\n",
       "      <td>12 Weeks, 24 Lessons, IoT for All!</td>\n",
       "      <td>713</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NationalSecurityAgency / ghidra</td>\n",
       "      <td>Ghidra is a software reverse engineering (SRE)...</td>\n",
       "      <td>89</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft / CBL-Mariner</td>\n",
       "      <td>Linux OS for Azure 1P services and edge applia...</td>\n",
       "      <td>225</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>opensearch-project / OpenSearch</td>\n",
       "      <td>Open source distributed and RESTful search eng...</td>\n",
       "      <td>783</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avelino / awesome-go</td>\n",
       "      <td>A curated list of awesome Go frameworks, libra...</td>\n",
       "      <td>346</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fenixsoft / awesome-fenix</td>\n",
       "      <td>讨论如何构建一套可靠的大型分布式系统</td>\n",
       "      <td>25</td>\n",
       "      <td>Vue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dromara / Sa-Token</td>\n",
       "      <td>这可能是史上功能最全的Java权限认证框架！目前已集成——登录认证、权限认证、分布式Sess...</td>\n",
       "      <td>529</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0vercl0k / wtf</td>\n",
       "      <td>wtf is a distributed, code-coverage guided, cu...</td>\n",
       "      <td>81</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TencentARC / GFPGAN</td>\n",
       "      <td>12 weeks, 24 lessons, classic Machine Learning...</td>\n",
       "      <td>131</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>microsoft / ML-For-Beginners</td>\n",
       "      <td>专门为刚开始刷题的同学准备的算法基地，没有最细只有更细，立志用动画将晦涩难懂的算法说的通俗易懂！</td>\n",
       "      <td>35</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chefyuan / algorithm-base</td>\n",
       "      <td>End-to-end image segmentation kit based on Pad...</td>\n",
       "      <td>82</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PaddlePaddle / PaddleSeg</td>\n",
       "      <td>微信消息解密工具</td>\n",
       "      <td>82</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JustYoomoon / WechatDecrypt</td>\n",
       "      <td> Now we have become very big, Different from ...</td>\n",
       "      <td>44</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jaywcjlove / awesome-mac</td>\n",
       "      <td>🇨🇳 GitHub中文排行榜，帮助你发现高分优秀中文项目、更高效地吸收国人的优秀经验成果；榜...</td>\n",
       "      <td>567</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kon9chunkit / GitHub-Chinese-Top-Charts</td>\n",
       "      <td>Used to integrate the Facebook Platform with y...</td>\n",
       "      <td>152</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>facebook / facebook-ios-sdk</td>\n",
       "      <td>A Go framework for microservices.</td>\n",
       "      <td>144</td>\n",
       "      <td>Objective-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>go-kratos / kratos</td>\n",
       "      <td>A cat(1) clone with wings.</td>\n",
       "      <td>None</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sharkdp / bat</td>\n",
       "      <td>This repository contains all the DSA (Data-Str...</td>\n",
       "      <td>None</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Aaron-lv / sync</td>\n",
       "      <td>Model parallel transformers in JAX and Haiku</td>\n",
       "      <td>None</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AkashSingh3031 / The-Complete-FAANG-Preparation</td>\n",
       "      <td>An open source vector database powered by Fais...</td>\n",
       "      <td>None</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kingoflolz / mesh-transformer-jax</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>smiek2221 / scripts</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>milvus-io / milvus</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Repository title  \\\n",
       "0                                  bndw / wifi-card   \n",
       "1                                  facebook / folly   \n",
       "2                     microsoft / IoT-For-Beginners   \n",
       "3                   NationalSecurityAgency / ghidra   \n",
       "4                           microsoft / CBL-Mariner   \n",
       "5                   opensearch-project / OpenSearch   \n",
       "6                              avelino / awesome-go   \n",
       "7                         fenixsoft / awesome-fenix   \n",
       "8                                dromara / Sa-Token   \n",
       "9                                    0vercl0k / wtf   \n",
       "10                              TencentARC / GFPGAN   \n",
       "11                     microsoft / ML-For-Beginners   \n",
       "12                        chefyuan / algorithm-base   \n",
       "13                         PaddlePaddle / PaddleSeg   \n",
       "14                      JustYoomoon / WechatDecrypt   \n",
       "15                         jaywcjlove / awesome-mac   \n",
       "16          kon9chunkit / GitHub-Chinese-Top-Charts   \n",
       "17                      facebook / facebook-ios-sdk   \n",
       "18                               go-kratos / kratos   \n",
       "19                                    sharkdp / bat   \n",
       "20                                  Aaron-lv / sync   \n",
       "21  AkashSingh3031 / The-Complete-FAANG-Preparation   \n",
       "22                kingoflolz / mesh-transformer-jax   \n",
       "23                              smiek2221 / scripts   \n",
       "24                               milvus-io / milvus   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0       📶 Print a QR code for connecting to your WiFi                124   \n",
       "1   An open-source C++ library developed and used ...                298   \n",
       "2                  12 Weeks, 24 Lessons, IoT for All!                713   \n",
       "3   Ghidra is a software reverse engineering (SRE)...                 89   \n",
       "4   Linux OS for Azure 1P services and edge applia...                225   \n",
       "5   Open source distributed and RESTful search eng...                783   \n",
       "6   A curated list of awesome Go frameworks, libra...                346   \n",
       "7                                  讨论如何构建一套可靠的大型分布式系统                 25   \n",
       "8   这可能是史上功能最全的Java权限认证框架！目前已集成——登录认证、权限认证、分布式Sess...                529   \n",
       "9   wtf is a distributed, code-coverage guided, cu...                 81   \n",
       "10  12 weeks, 24 lessons, classic Machine Learning...                131   \n",
       "11   专门为刚开始刷题的同学准备的算法基地，没有最细只有更细，立志用动画将晦涩难懂的算法说的通俗易懂！                 35   \n",
       "12  End-to-end image segmentation kit based on Pad...                 82   \n",
       "13                                           微信消息解密工具                 82   \n",
       "14   Now we have become very big, Different from ...                 44   \n",
       "15  🇨🇳 GitHub中文排行榜，帮助你发现高分优秀中文项目、更高效地吸收国人的优秀经验成果；榜...                567   \n",
       "16  Used to integrate the Facebook Platform with y...                152   \n",
       "17                  A Go framework for microservices.                144   \n",
       "18                         A cat(1) clone with wings.               None   \n",
       "19  This repository contains all the DSA (Data-Str...               None   \n",
       "20       Model parallel transformers in JAX and Haiku               None   \n",
       "21  An open source vector database powered by Fais...               None   \n",
       "22                                               None               None   \n",
       "23                                               None               None   \n",
       "24                                               None               None   \n",
       "\n",
       "       Language used  \n",
       "0         JavaScript  \n",
       "1                C++  \n",
       "2                C++  \n",
       "3               Java  \n",
       "4                 Go  \n",
       "5               Java  \n",
       "6                 Go  \n",
       "7                Vue  \n",
       "8               Java  \n",
       "9                C++  \n",
       "10            Python  \n",
       "11  Jupyter Notebook  \n",
       "12              Java  \n",
       "13            Python  \n",
       "14               C++  \n",
       "15        JavaScript  \n",
       "16              Java  \n",
       "17       Objective-C  \n",
       "18                Go  \n",
       "19              Rust  \n",
       "20  Jupyter Notebook  \n",
       "21            Python  \n",
       "22        JavaScript  \n",
       "23                Go  \n",
       "24              None  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "\n",
    "# Opening the homepage of billboard.com\n",
    "url='https://www.billboard.com/charts/hot-100'\n",
    "driver.get(url)\n",
    "\n",
    "# Extracting song_name from xpath\n",
    "song_name=driver.find_elements_by_xpath('//span[@class=\"chart-element__information__song text--truncate color--primary\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Song_Name=[]\n",
    "for j in song_name:\n",
    "    Song_Name.append(j.text)\n",
    "    \n",
    "# Extracting artist name from xpath\n",
    "artist_name=driver.find_elements_by_xpath('//span[@class=\"chart-element__information__artist text--truncate color--secondary\"]')\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Artist_Name=[]\n",
    "for j in artist_name:\n",
    "    Artist_Name.append(j.text)    \n",
    "    \n",
    "# Extracting last week from xpath\n",
    "last_week=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Last_Week=[]\n",
    "for j in last_week:\n",
    "    Last_Week.append(j.text) \n",
    "    \n",
    "# Extracting peak rank from xpath\n",
    "peak_rank=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Peak_Rank=[]\n",
    "for j in peak_rank:\n",
    "    Peak_Rank.append(j.text) \n",
    "    \n",
    "# Extracting weeks board from xpath\n",
    "weeks_board=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]') \n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Weeks_board=[]\n",
    "for j in weeks_board:\n",
    "    Weeks_board.append(j.text)  \n",
    "    \n",
    "# Make dataframe\n",
    "Billboard_songs = pd.DataFrame({'Song Name':Song_Name,'Artist_Name':Artist_Name,'Last week rank':Last_Week,\n",
    "                               'Peak rank':Peak_Rank,'Weeks on board':Weeks_board})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiss Me More</td>\n",
       "      <td>Doja Cat Featuring SZA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montero (Call Me By Your Name)</td>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>All I Know So Far</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>-</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>What's Next</td>\n",
       "      <td>Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Enough For You</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>-</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Juggernaut</td>\n",
       "      <td>Tyler, The Creator Featuring Lil Uzi Vert &amp; Ph...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tell Em</td>\n",
       "      <td>Cochise &amp; $NOT</td>\n",
       "      <td>-</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Song Name  \\\n",
       "0                           Butter   \n",
       "1                         Good 4 U   \n",
       "2                       Levitating   \n",
       "3                     Kiss Me More   \n",
       "4   Montero (Call Me By Your Name)   \n",
       "..                             ...   \n",
       "95               All I Know So Far   \n",
       "96                     What's Next   \n",
       "97                  Enough For You   \n",
       "98                      Juggernaut   \n",
       "99                         Tell Em   \n",
       "\n",
       "                                          Artist_Name Last week rank  \\\n",
       "0                                                 BTS              1   \n",
       "1                                      Olivia Rodrigo              2   \n",
       "2                           Dua Lipa Featuring DaBaby              4   \n",
       "3                              Doja Cat Featuring SZA              3   \n",
       "4                                           Lil Nas X              8   \n",
       "..                                                ...            ...   \n",
       "95                                               P!nk              -   \n",
       "96                                              Drake              -   \n",
       "97                                     Olivia Rodrigo              -   \n",
       "98  Tyler, The Creator Featuring Lil Uzi Vert & Ph...             40   \n",
       "99                                     Cochise & $NOT              -   \n",
       "\n",
       "   Peak rank Weeks on board  \n",
       "0          1              7  \n",
       "1          1              8  \n",
       "2          2             40  \n",
       "3          3             13  \n",
       "4          1             15  \n",
       "..       ...            ...  \n",
       "95        74              4  \n",
       "96         1             16  \n",
       "97        14              6  \n",
       "98        40              2  \n",
       "99        64              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billboard_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Opening the homepage of naukri.com\n",
    "url= 'https://www.naukri.com/hr-recruiters-consultants'\n",
    "driver.get(url)\n",
    "\n",
    "# finding element for job search bar\n",
    "search_job=driver.find_element_by_id('skill')\n",
    "search_job\n",
    "\n",
    "# do click using xpath function\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "search_btn.click()\n",
    "\n",
    "# extract all the tags having the name\n",
    "Name=[]\n",
    "name=driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\")\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for i in name:\n",
    "    Name.append(i.text)  \n",
    "    \n",
    "# extract all the tags having the designation\n",
    "Designation=[]\n",
    "designation=driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for i in designation:\n",
    "    Designation.append(i.text)    \n",
    "\n",
    "# extract all the tags having the skills\n",
    "Skills=[]\n",
    "skills=driver.find_elements_by_xpath(\"//p[@class='sklHd']\")\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for j in skills:\n",
    "    Skills.append(j.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the tags having the job_titles\n",
    "Lo=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "for j in location:\n",
    "    Lo.append(j.text)    \n",
    "Location[1:2]\n",
    "for j in location:\n",
    "    Lo.append(j.text)    \n",
    "Lo[1:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ahmedabad']\n",
      "['Mumbai']\n",
      "['Jaipur']\n",
      "['Gurgaon']\n",
      "['Pune']\n",
      "['Noida']\n",
      "['Mumbai']\n",
      "['Chennai']\n",
      "['Kolkata']\n",
      "['Kolhapur']\n",
      "['Kolkata']\n",
      "['Mumbai']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "Location1=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location1.append(j.text)    \n",
    "print(Location1[3:4])\n",
    "\n",
    "Location2=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location2.append(j.text)    \n",
    "print(Location2[5:6])\n",
    "\n",
    "Location3=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location3.append(j.text)    \n",
    "print(Location3[7:8])\n",
    "\n",
    "Location4=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location4.append(j.text)    \n",
    "print(Location4[9:10])\n",
    "\n",
    "\n",
    "Location5=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location5.append(j.text)    \n",
    "print(Location5[11:12])\n",
    "\n",
    "Location6=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location6.append(j.text)    \n",
    "print(Location6[13:14])\n",
    "\n",
    "Location7=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location7.append(j.text)    \n",
    "print(Location7[15:16])\n",
    "\n",
    "Location8=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location8.append(j.text)    \n",
    "print(Location8[17:18])\n",
    "\n",
    "Location9=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location9.append(j.text)    \n",
    "print(Location9[19:20])\n",
    "\n",
    "Location10=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location10.append(j.text)    \n",
    "print(Location10[21:22])\n",
    "\n",
    "Location11=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location11.append(j.text)    \n",
    "print(Location11[23:24])\n",
    "\n",
    "Location12=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location12.append(j.text)    \n",
    "print(Location12[25:26])\n",
    "\n",
    "Location13=[]\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in location:\n",
    "    Location13.append(j.text)    \n",
    "print(Location13[27:28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location=['Chennai','Ahmedabad','Mumbai','Jaipur','Gurgaon','Pune','Noida','Mumbai','Chennai','Mumbai','Hyderabad / Secunderabad',\n",
    "         'Kolhapur','Kolkata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai',\n",
       " 'Ahmedabad',\n",
       " 'Mumbai',\n",
       " 'Jaipur',\n",
       " 'Gurgaon',\n",
       " 'Pune',\n",
       " 'Noida',\n",
       " 'Mumbai',\n",
       " 'Chennai',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Kolhapur',\n",
       " 'Kolkata']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maveric Systems']\n",
      "['Primacy Systems Pvt Ltd']\n",
      "['TCRC']\n",
      "['PADHAI HELP PRIVATE LIMITED']\n",
      "['Ingenious E-Brain Solutions Private Limited']\n",
      "['Xpansion HR Solutions Private Limited']\n",
      "['Samsung']\n",
      "['Rubicon Research']\n",
      "['S & P Foundation Private Limited,']\n",
      "['Kaizen IT Services Pvt. Ltd.']\n",
      "['SLK Global Solutions Pvt Ltd']\n",
      "['prameya education pvt ltd']\n",
      "['Brennan IT']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "cmp=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp.append(j.text)    \n",
    "print(cmp[0:1])\n",
    "\n",
    "\n",
    "cmp1=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp1.append(j.text)    \n",
    "print(cmp1[2:3])\n",
    "\n",
    "cmp2=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp2.append(j.text)    \n",
    "print(cmp2[4:5])\n",
    "\n",
    "cmp3=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp3.append(j.text)    \n",
    "print(cmp3[6:7])\n",
    "\n",
    "cmp4=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp4.append(j.text)    \n",
    "print(cmp4[8:9])\n",
    "\n",
    "cmp5=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp5.append(j.text)    \n",
    "print(cmp5[10:11])\n",
    "\n",
    "cmp6=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp6.append(j.text)    \n",
    "print(cmp6[12:13])\n",
    "\n",
    "cmp7=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp7.append(j.text)    \n",
    "print(cmp7[14:15])\n",
    "\n",
    "cmp8=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp8.append(j.text)    \n",
    "print(cmp8[16:17])\n",
    "\n",
    "cmp9=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp9.append(j.text)    \n",
    "print(cmp9[18:19])\n",
    "\n",
    "cmp10=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp10.append(j.text)    \n",
    "print(cmp10[20:21])\n",
    "\n",
    "cmp11=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp11.append(j.text)    \n",
    "print(cmp11[22:23])\n",
    "\n",
    "cmp12=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp12.append(j.text)    \n",
    "print(cmp12[24:25])\n",
    "\n",
    "cmp13=[]\n",
    "company=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for j in company:\n",
    "    cmp13.append(j.text)    \n",
    "print(cmp13[26:27])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "Company=['Maveric Systems','Primacy Systems Pvt Ltd','TCRC','PADHAI HELP PRIVATE LIMITED','Ingenious E-Brain Solutions Private Limited'\n",
    "        'Xpansion HR Solutions Private Limited','Samsung','Rubicon Research','S & P Foundation Private Limited','Brennan IT',\n",
    "        'himanshu enterprises','SLK Global Solutions Pvt Ltd','Kaizen IT Services Pvt. Ltd.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maveric Systems',\n",
       " 'Primacy Systems Pvt Ltd',\n",
       " 'TCRC',\n",
       " 'PADHAI HELP PRIVATE LIMITED',\n",
       " 'Ingenious E-Brain Solutions Private LimitedXpansion HR Solutions Private Limited',\n",
       " 'Samsung',\n",
       " 'Rubicon Research',\n",
       " 'S & P Foundation Private Limited',\n",
       " 'Brennan IT',\n",
       " 'himanshu enterprises',\n",
       " 'SLK Global Solutions Pvt Ltd',\n",
       " 'Kaizen IT Services Pvt. Ltd.']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe\n",
    "a  = {'Name':Name,   'Designation':Designation,  'Company':Company,  'Location':Location,  'Skills they hire for':Skills}\n",
    "jobs_data=pd.DataFrame.from_dict(a, orient='index')\n",
    "jobs_data=jobs_data.transpose()                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills they hire for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santhosh Kumar</td>\n",
       "      <td>Associate Manager Human Resources</td>\n",
       "      <td>Maveric Systems</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Skills/Roles I hire for :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanghvi</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Primacy Systems Pvt Ltd</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Skills/Roles I hire for :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gauri Bhosle</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>TCRC</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Skills/Roles I hire for :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Khandelwal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>PADHAI HELP PRIVATE LIMITED</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Skills/Roles I hire for :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neha Pandey</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Ingenious E-Brain Solutions Private LimitedXpa...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Skills/Roles I hire for :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vinita Raut</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Skills/Roles I hire for :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sanjay Desai</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Rubicon Research</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Skills/Roles I hire for :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Susheel Sonar</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>S &amp; P Foundation Private Limited</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Skills/Roles I hire for :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SREENIVASA PERUMAL K N</td>\n",
       "      <td>Senior Manager HR Admin</td>\n",
       "      <td>Brennan IT</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Niraj Thakur</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>himanshu enterprises</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nitin R Patil</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>SLK Global Solutions Pvt Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dipak jha</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Kaizen IT Services Pvt. Ltd.</td>\n",
       "      <td>Kolhapur</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dilip Joshi</td>\n",
       "      <td>Talent Acquisition Specialist</td>\n",
       "      <td>None</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name                        Designation  \\\n",
       "0           Santhosh Kumar  Associate Manager Human Resources   \n",
       "1                  Sanghvi                  Company Recruiter   \n",
       "2             Gauri Bhosle                    Human Resources   \n",
       "3         Rohit Khandelwal                  Company Recruiter   \n",
       "4              Neha Pandey                  Company Recruiter   \n",
       "5              Vinita Raut                  Company Recruiter   \n",
       "6             Sanjay Desai             Human Resource Manager   \n",
       "7            Susheel Sonar                    Human Resources   \n",
       "8   SREENIVASA PERUMAL K N            Senior Manager HR Admin   \n",
       "9             Niraj Thakur                         Company HR   \n",
       "10           Nitin R Patil                         Company HR   \n",
       "11               dipak jha                         Company HR   \n",
       "12             Dilip Joshi      Talent Acquisition Specialist   \n",
       "\n",
       "                                              Company  \\\n",
       "0                                     Maveric Systems   \n",
       "1                             Primacy Systems Pvt Ltd   \n",
       "2                                                TCRC   \n",
       "3                         PADHAI HELP PRIVATE LIMITED   \n",
       "4   Ingenious E-Brain Solutions Private LimitedXpa...   \n",
       "5                                             Samsung   \n",
       "6                                    Rubicon Research   \n",
       "7                    S & P Foundation Private Limited   \n",
       "8                                          Brennan IT   \n",
       "9                                himanshu enterprises   \n",
       "10                       SLK Global Solutions Pvt Ltd   \n",
       "11                       Kaizen IT Services Pvt. Ltd.   \n",
       "12                                               None   \n",
       "\n",
       "                    Location       Skills they hire for  \n",
       "0                    Chennai  Skills/Roles I hire for :  \n",
       "1                  Ahmedabad  Skills/Roles I hire for :  \n",
       "2                     Mumbai  Skills/Roles I hire for :  \n",
       "3                     Jaipur  Skills/Roles I hire for :  \n",
       "4                    Gurgaon  Skills/Roles I hire for :  \n",
       "5                       Pune  Skills/Roles I hire for :  \n",
       "6                      Noida  Skills/Roles I hire for :  \n",
       "7                     Mumbai  Skills/Roles I hire for :  \n",
       "8                    Chennai                       None  \n",
       "9                     Mumbai                       None  \n",
       "10  Hyderabad / Secunderabad                       None  \n",
       "11                  Kolhapur                       None  \n",
       "12                   Kolkata                       None  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_data[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of imdb.com\n",
    "url= 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting book-name from xpath\n",
    "title = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-0-1\"]')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Da Vinci Code,The']\n",
      "['Harry Potter and the Deathly Hallows']\n",
      "[\"Harry Potter and the Philosopher's Stone\"]\n",
      "['Harry Potter and the Order of the Phoenix']\n",
      "['Fifty Shades of Grey']\n",
      "['Harry Potter and the Goblet of Fire']\n",
      "['Harry Potter and the Chamber of Secrets']\n",
      "['Harry Potter and the Prisoner of Azkaban']\n",
      "['Angels and Demons']\n",
      "[\"Harry Potter and the Half-blood Prince:Children's Edition\"]\n",
      "['Fifty Shades Darker']\n",
      "['Twilight']\n",
      "['Girl with the Dragon Tattoo,The:Millennium Trilogy']\n",
      "['Fifty Shades Freed']\n",
      "['Lost Symbol,The']\n",
      "['New Moon']\n"
     ]
    }
   ],
   "source": [
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "T1=[]\n",
    "for j in title:\n",
    "    T1.append(j.text)\n",
    "print(T1)\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title1 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-1-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title1=[]\n",
    "for j in title1:\n",
    "    Title1.append(j.text)\n",
    "print(Title1)   \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title2 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-2-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title2=[]\n",
    "for j in title2:\n",
    "    Title2.append(j.text)\n",
    "print(Title2) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title3 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-3-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title3=[]\n",
    "for j in title3:\n",
    "    Title3.append(j.text)\n",
    "print(Title3) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title4 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-4-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title4=[]\n",
    "for j in title4:\n",
    "    Title4.append(j.text)\n",
    "print(Title4) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title5 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-5-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title5=[]\n",
    "for j in title5:\n",
    "    Title5.append(j.text)\n",
    "print(Title5)\n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title6 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-6-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title6=[]\n",
    "for j in title6:\n",
    "    Title6.append(j.text)\n",
    "print(Title6) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title7 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-7-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title7=[]\n",
    "for j in title7:\n",
    "    Title7.append(j.text)\n",
    "print(Title7) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title8 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-8-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title8=[]\n",
    "for j in title8:\n",
    "    Title8.append(j.text)\n",
    "print(Title8) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title9 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-9-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title9=[]\n",
    "for j in title9:\n",
    "    Title9.append(j.text)\n",
    "print(Title9) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title10 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-10-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title10=[]\n",
    "for j in title10:\n",
    "    Title10.append(j.text)\n",
    "print(Title10) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title11 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-11-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title11=[]\n",
    "for j in title11:\n",
    "    Title11.append(j.text)\n",
    "print(Title11) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title12 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-12-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title12=[]\n",
    "for j in title12:\n",
    "    Title12.append(j.text)\n",
    "print(Title12) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title13 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-13-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title13=[]\n",
    "for j in title13:\n",
    "    Title13.append(j.text)\n",
    "print(Title13) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title14 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-14-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title14=[]\n",
    "for j in title14:\n",
    "    Title14.append(j.text)\n",
    "print(Title14) \n",
    "\n",
    "\n",
    "# Extracting book-name from xpath\n",
    "title15 = driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-15-1\"]')\n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Title15=[]\n",
    "for j in title15:\n",
    "    Title15.append(j.text)\n",
    "print(Title15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting author-name from xpath\n",
    "author_name= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-0-2\"]')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brown, Dan']\n",
      "['Rowling, J.K.']\n",
      "['Rowling, J.K.']\n",
      "['Rowling, J.K.']\n",
      "['James, E. L.']\n",
      "['Rowling, J.K.']\n",
      "['Rowling, J.K.']\n",
      "['Rowling, J.K.']\n",
      "['Brown, Dan']\n",
      "['Rowling, J.K.']\n",
      "['James, E. L.']\n",
      "['Meyer, Stephenie']\n",
      "['Larsson, Stieg']\n",
      "['James, E. L.']\n",
      "['Brown, Dan']\n",
      "['Meyer, Stephenie']\n"
     ]
    }
   ],
   "source": [
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_name=[]\n",
    "for j in author_name:\n",
    "    Author_name.append(j.text)\n",
    "print(Author_name)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name1= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-1-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name1=[]\n",
    "for j in author_name1:\n",
    "    Author_Name1.append(j.text)\n",
    "print(Author_Name1)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name2= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-2-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name2=[]\n",
    "for j in author_name2:\n",
    "    Author_Name2.append(j.text)\n",
    "print(Author_Name2)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name3= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-3-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name3=[]\n",
    "for j in author_name3:\n",
    "    Author_Name3.append(j.text)\n",
    "print(Author_Name3)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name4= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-4-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name4=[]\n",
    "for j in author_name4:\n",
    "    Author_Name4.append(j.text)\n",
    "print(Author_Name4)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name5= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-5-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name5=[]\n",
    "for j in author_name5:\n",
    "    Author_Name5.append(j.text)\n",
    "print(Author_Name5)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name6= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-6-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name6=[]\n",
    "for j in author_name6:\n",
    "    Author_Name6.append(j.text)\n",
    "print(Author_Name6)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name7= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-7-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name7=[]\n",
    "for j in author_name7:\n",
    "    Author_Name7.append(j.text)\n",
    "print(Author_Name7)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name8= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-8-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name8=[]\n",
    "for j in author_name8:\n",
    "    Author_Name8.append(j.text)\n",
    "print(Author_Name8)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name9= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-9-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name9=[]\n",
    "for j in author_name9:\n",
    "    Author_Name9.append(j.text)\n",
    "print(Author_Name9)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name10= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-10-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name10=[]\n",
    "for j in author_name10:\n",
    "    Author_Name10.append(j.text)\n",
    "print(Author_Name10)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name11= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-11-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name11=[]\n",
    "for j in author_name11:\n",
    "    Author_Name11.append(j.text)\n",
    "print(Author_Name11)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name12= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-12-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name12=[]\n",
    "for j in author_name12:\n",
    "    Author_Name12.append(j.text)\n",
    "print(Author_Name12)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name13= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-13-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name13=[]\n",
    "for j in author_name13:\n",
    "    Author_Name13.append(j.text)\n",
    "print(Author_Name13)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name14= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-14-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name14=[]\n",
    "for j in author_name14:\n",
    "    Author_Name14.append(j.text)\n",
    "print(Author_Name14)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "author_name15= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-15-2\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Author_Name15=[]\n",
    "for j in author_name15:\n",
    "    Author_Name15.append(j.text)\n",
    "print(Author_Name15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting author-name from xpath\n",
    "volume_sales= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-0-3\"]')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5,094,805']\n",
      "['4,475,152']\n",
      "['4,200,654']\n",
      "['4,179,479']\n",
      "['3,758,936']\n",
      "['3,583,215']\n",
      "['3,484,047']\n",
      "['3,377,906']\n",
      "['3,193,946']\n",
      "['2,950,264']\n",
      "['2,479,784']\n",
      "['2,315,405']\n",
      "['2,233,570']\n",
      "['2,193,928']\n",
      "['2,183,031']\n",
      "['2,152,737']\n",
      "['2,062,145']\n"
     ]
    }
   ],
   "source": [
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_sales=[]\n",
    "for j in volume_sales:\n",
    "    Volume_sales.append(j.text)\n",
    "print(Volume_sales)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales1= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-1-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales1=[]\n",
    "for j in volume_sales1:\n",
    "    Volume_Sales1.append(j.text)\n",
    "print(Volume_Sales1)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales2= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-2-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales2=[]\n",
    "for j in volume_sales2:\n",
    "    Volume_Sales2.append(j.text)\n",
    "print(Volume_Sales2)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales3= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-3-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales3=[]\n",
    "for j in volume_sales3:\n",
    "    Volume_Sales3.append(j.text)\n",
    "print(Volume_Sales3)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales4= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-4-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales4=[]\n",
    "for j in volume_sales4:\n",
    "    Volume_Sales4.append(j.text)\n",
    "print(Volume_Sales4)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales5= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-5-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales5=[]\n",
    "for j in volume_sales5:\n",
    "    Volume_Sales5.append(j.text)\n",
    "print(Volume_Sales5)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales6= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-6-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales6=[]\n",
    "for j in volume_sales6:\n",
    "    Volume_Sales6.append(j.text)\n",
    "print(Volume_Sales6)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales7= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-7-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales7=[]\n",
    "for j in volume_sales7:\n",
    "    Volume_Sales7.append(j.text)\n",
    "print(Volume_Sales7)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales8= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-8-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales8=[]\n",
    "for j in volume_sales8:\n",
    "    Volume_Sales8.append(j.text)\n",
    "print(Volume_Sales8)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales9= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-9-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales9=[]\n",
    "for j in volume_sales9:\n",
    "    Volume_Sales9.append(j.text)\n",
    "print(Volume_Sales9)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales10= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-10-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales10=[]\n",
    "for j in volume_sales10:\n",
    "    Volume_Sales10.append(j.text)\n",
    "print(Volume_Sales10)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales11= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-11-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales11=[]\n",
    "for j in volume_sales11:\n",
    "    Volume_Sales11.append(j.text)\n",
    "print(Volume_Sales11)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales12= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-12-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales12=[]\n",
    "for j in volume_sales12:\n",
    "    Volume_Sales12.append(j.text)\n",
    "print(Volume_Sales12)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales13= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-13-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales13=[]\n",
    "for j in volume_sales13:\n",
    "    Volume_Sales13.append(j.text)\n",
    "print(Volume_Sales13)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales14= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-14-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales14=[]\n",
    "for j in volume_sales14:\n",
    "    Volume_Sales14.append(j.text)\n",
    "print(Volume_Sales14)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales15= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-15-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales15=[]\n",
    "for j in volume_sales15:\n",
    "    Volume_Sales15.append(j.text)\n",
    "print(Volume_Sales15)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "volume_sales16= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-16-3\"]')  \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Volume_Sales16=[]\n",
    "for j in volume_sales16:\n",
    "    Volume_Sales16.append(j.text)\n",
    "print(Volume_Sales16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting author-name from xpath\n",
    "publisher= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-0-4\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bloomsbury']\n",
      "['Bloomsbury']\n",
      "['Bloomsbury']\n",
      "['Random House']\n",
      "['Bloomsbury']\n",
      "['Bloomsbury']\n",
      "['Bloomsbury']\n",
      "['Transworld']\n",
      "['Bloomsbury']\n",
      "['Random House']\n",
      "['Little, Brown Book']\n",
      "['Quercus']\n",
      "['Random House']\n",
      "['Transworld']\n",
      "['Little, Brown Book']\n",
      "['Transworld']\n"
     ]
    }
   ],
   "source": [
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publish=[]\n",
    "for j in publisher:\n",
    "    Publish.append(j.text)\n",
    "Publish\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher1= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-1-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher1=[]\n",
    "for j in publisher1:\n",
    "    Publisher1.append(j.text)\n",
    "print(Publisher1)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher2= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-2-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher2=[]\n",
    "for j in publisher2:\n",
    "    Publisher2.append(j.text)\n",
    "print(Publisher2)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher3= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-3-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher3=[]\n",
    "for j in publisher3:\n",
    "    Publisher3.append(j.text)\n",
    "print(Publisher3)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher4= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-4-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher4=[]\n",
    "for j in publisher4:\n",
    "    Publisher4.append(j.text)\n",
    "print(Publisher4)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher5= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-5-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher5=[]\n",
    "for j in publisher5:\n",
    "    Publisher5.append(j.text)\n",
    "print(Publisher5)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher6= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-6-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher6=[]\n",
    "for j in publisher6:\n",
    "    Publisher6.append(j.text)\n",
    "print(Publisher6)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher7= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-7-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher7=[]\n",
    "for j in publisher7:\n",
    "    Publisher7.append(j.text)\n",
    "print(Publisher7)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher8= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-8-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher8=[]\n",
    "for j in publisher8:\n",
    "    Publisher8.append(j.text)\n",
    "print(Publisher8)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher9= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-9-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher9=[]\n",
    "for j in publisher9:\n",
    "    Publisher9.append(j.text)\n",
    "print(Publisher9)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher10= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-10-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher10=[]\n",
    "for j in publisher10:\n",
    "    Publisher10.append(j.text)\n",
    "print(Publisher10)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher11= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-11-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher11=[]\n",
    "for j in publisher11:\n",
    "    Publisher11.append(j.text)\n",
    "print(Publisher11)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher12= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-12-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher12=[]\n",
    "for j in publisher12:\n",
    "    Publisher12.append(j.text)\n",
    "print(Publisher12)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher13= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-13-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher13=[]\n",
    "for j in publisher13:\n",
    "    Publisher13.append(j.text)\n",
    "print(Publisher13)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher14= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-14-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher14=[]\n",
    "for j in publisher14:\n",
    "    Publisher14.append(j.text)\n",
    "print(Publisher14)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher15= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-15-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher15=[]\n",
    "for j in publisher15:\n",
    "    Publisher15.append(j.text)\n",
    "print(Publisher15)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "publisher16= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-16-4\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Publisher16=[]\n",
    "for j in publisher16:\n",
    "    Publisher16.append(j.text)\n",
    "print(Publisher16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting author-name from xpath\n",
    "genre= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-0-5\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Crime, Thriller & Adventure']\n",
      "[\"Children's Fiction\"]\n",
      "[\"Children's Fiction\"]\n",
      "[\"Children's Fiction\"]\n",
      "['Romance & Sagas']\n",
      "[\"Children's Fiction\"]\n",
      "[\"Children's Fiction\"]\n",
      "[\"Children's Fiction\"]\n",
      "['Crime, Thriller & Adventure']\n",
      "[\"Children's Fiction\"]\n",
      "['Romance & Sagas']\n",
      "['Young Adult Fiction']\n",
      "['Crime, Thriller & Adventure']\n",
      "['Romance & Sagas']\n",
      "['Crime, Thriller & Adventure']\n",
      "['Young Adult Fiction']\n"
     ]
    }
   ],
   "source": [
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Gen=[]\n",
    "for j in genre:\n",
    "    Gen.append(j.text)\n",
    "print(Gen)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre1= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-1-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre1=[]\n",
    "for j in genre1:\n",
    "    Genre1.append(j.text)\n",
    "print(Genre1)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre2= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-2-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre2=[]\n",
    "for j in genre2:\n",
    "    Genre2.append(j.text)\n",
    "print(Genre2)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre3= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-3-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre3=[]\n",
    "for j in genre3:\n",
    "    Genre3.append(j.text)\n",
    "print(Genre3)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre4= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-4-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre4=[]\n",
    "for j in genre4:\n",
    "    Genre4.append(j.text)\n",
    "print(Genre4)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre5= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-5-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre5=[]\n",
    "for j in genre5:\n",
    "    Genre5.append(j.text)\n",
    "print(Genre5)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre6= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-6-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre6=[]\n",
    "for j in genre6:\n",
    "    Genre6.append(j.text)\n",
    "print(Genre6)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre7= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-7-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre7=[]\n",
    "for j in genre7:\n",
    "    Genre7.append(j.text)\n",
    "print(Genre7)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre8= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-8-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre8=[]\n",
    "for j in genre8:\n",
    "    Genre8.append(j.text)\n",
    "print(Genre8)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre9= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-9-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre9=[]\n",
    "for j in genre9:\n",
    "    Genre9.append(j.text)\n",
    "print(Genre9)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre10= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-10-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre10=[]\n",
    "for j in genre10:\n",
    "    Genre10.append(j.text)\n",
    "print(Genre10)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre11= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-11-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre11=[]\n",
    "for j in genre11:\n",
    "    Genre11.append(j.text)\n",
    "print(Genre11)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre12= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-12-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre12=[]\n",
    "for j in genre12:\n",
    "    Genre12.append(j.text)\n",
    "print(Genre12)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre13= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-13-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre13=[]\n",
    "for j in genre13:\n",
    "    Genre13.append(j.text)\n",
    "print(Genre13)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre14= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-14-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre14=[]\n",
    "for j in genre14:\n",
    "    Genre14.append(j.text)\n",
    "print(Genre14)\n",
    "\n",
    "# Extracting author-name from xpath\n",
    "genre15= driver.find_elements_by_xpath('//td[@id=\"table-cell-10943-15-5\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre15=[]\n",
    "for j in genre15:\n",
    "    Genre15.append(j.text)\n",
    "print(Genre15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=['Da Vinci Code,The',\n",
    "'Harry Potter and the Deathly Hallows',\n",
    "\"Harry Potter and the Philosopher's Stone\",\n",
    "'Harry Potter and the Order of the Phoenix',\n",
    "'Fifty Shades of Grey',\n",
    "'Harry Potter and the Goblet of Fire',\n",
    "'Harry Potter and the Chamber of Secrets',\n",
    "'Harry Potter and the Prisoner of Azkaban',\n",
    "'Angels and Demons',\n",
    "\"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
    "'Fifty Shades Darker',\n",
    "'Twilight',\n",
    "'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
    "'Fifty Shades Freed',\n",
    "'Lost Symbol,The',\n",
    "'New Moon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "Author_Name=['Brown, Dan',\n",
    "'Rowling, J.K.',\n",
    "'Rowling, J.K.',\n",
    "'Rowling, J.K.',\n",
    "'James, E. L.',\n",
    "'Rowling, J.K.',\n",
    "'Rowling, J.K.',\n",
    "'Rowling, J.K.',\n",
    "'Brown, Dan',\n",
    "'Rowling, J.K.',\n",
    "'James, E. L.',\n",
    "'Meyer, Stephenie',\n",
    "'Larsson, Stieg',\n",
    "'James, E. L.',\n",
    "'Brown, Dan',\n",
    "'Meyer, Stephenie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Author_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume_Sales=['5,094,805',\n",
    "'4,475,152',\n",
    "'4,200,654',\n",
    "'4,179,479',\n",
    "'3,758,936',\n",
    "'3,583,215',\n",
    "'3,484,047',\n",
    "'3,377,906',\n",
    "'3,193,946',\n",
    "'2,950,264',\n",
    "'2,479,784',\n",
    "'2,315,405',\n",
    "'2,233,570',\n",
    "'2,193,928',\n",
    "'2,183,031'\n",
    "'2,152,737',\n",
    " '2,062,145'            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,0312,152,737',\n",
       " '2,062,145']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Volume_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Publisher=['Bloomsbury',\n",
    "'Bloomsbury',\n",
    "'Bloomsbury',\n",
    "'Random House',\n",
    "'Bloomsbury',\n",
    "'Bloomsbury',\n",
    "'Bloomsbury',\n",
    "'Transworld',\n",
    "'Bloomsbury',\n",
    "'Random House',\n",
    "'Little, Brown Book',\n",
    "'Quercus',\n",
    "'Random House',\n",
    "'Transworld',\n",
    "'Little, Brown Book',\n",
    " 'Transworld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre=['Crime, Thriller & Adventure',\n",
    "\"Children's Fiction\",\n",
    "\"Children's Fiction\",\n",
    "\"Children's Fiction\",\n",
    "'Romance & Sagas',\n",
    "\"Children's Fiction\",\n",
    "\"Children's Fiction\",\n",
    "\"Children's Fiction\",\n",
    "'Crime, Thriller & Adventure',\n",
    "\"Children's Fiction\",\n",
    "'Romance & Sagas',\n",
    "'Young Adult Fiction',\n",
    "'Crime, Thriller & Adventure',\n",
    "'Romance & Sagas',\n",
    "'Crime, Thriller & Adventure',\n",
    "'Young Adult Fiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a DataFrame\n",
    "a={'Book Name':Title,   'Genre':Genre,   'Author Name':Author_Name,   'Volume_Sales':Volume_Sales,   'Publisher':Publisher}\n",
    "Selling_novels=pd.DataFrame.from_dict(a, orient='index')\n",
    "Selling_novels=Selling_novels.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume_Sales</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,583,215</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,484,047</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,377,906</td>\n",
       "      <td>Transworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Angels and Demons</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>3,193,946</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harry Potter and the Half-blood Prince:Childre...</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>2,950,264</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fifty Shades Darker</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,479,784</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,315,405</td>\n",
       "      <td>Quercus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Girl with the Dragon Tattoo,The:Millennium Tri...</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "      <td>Larsson, Stieg</td>\n",
       "      <td>2,233,570</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fifty Shades Freed</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,193,928</td>\n",
       "      <td>Transworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lost Symbol,The</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>2,183,0312,152,737</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New Moon</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,062,145</td>\n",
       "      <td>Transworld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name  \\\n",
       "0                                   Da Vinci Code,The   \n",
       "1                Harry Potter and the Deathly Hallows   \n",
       "2            Harry Potter and the Philosopher's Stone   \n",
       "3           Harry Potter and the Order of the Phoenix   \n",
       "4                                Fifty Shades of Grey   \n",
       "5                 Harry Potter and the Goblet of Fire   \n",
       "6             Harry Potter and the Chamber of Secrets   \n",
       "7            Harry Potter and the Prisoner of Azkaban   \n",
       "8                                   Angels and Demons   \n",
       "9   Harry Potter and the Half-blood Prince:Childre...   \n",
       "10                                Fifty Shades Darker   \n",
       "11                                           Twilight   \n",
       "12  Girl with the Dragon Tattoo,The:Millennium Tri...   \n",
       "13                                 Fifty Shades Freed   \n",
       "14                                    Lost Symbol,The   \n",
       "15                                           New Moon   \n",
       "\n",
       "                          Genre       Author Name        Volume_Sales  \\\n",
       "0   Crime, Thriller & Adventure        Brown, Dan           5,094,805   \n",
       "1            Children's Fiction     Rowling, J.K.           4,475,152   \n",
       "2            Children's Fiction     Rowling, J.K.           4,200,654   \n",
       "3            Children's Fiction     Rowling, J.K.           4,179,479   \n",
       "4               Romance & Sagas      James, E. L.           3,758,936   \n",
       "5            Children's Fiction     Rowling, J.K.           3,583,215   \n",
       "6            Children's Fiction     Rowling, J.K.           3,484,047   \n",
       "7            Children's Fiction     Rowling, J.K.           3,377,906   \n",
       "8   Crime, Thriller & Adventure        Brown, Dan           3,193,946   \n",
       "9            Children's Fiction     Rowling, J.K.           2,950,264   \n",
       "10              Romance & Sagas      James, E. L.           2,479,784   \n",
       "11          Young Adult Fiction  Meyer, Stephenie           2,315,405   \n",
       "12  Crime, Thriller & Adventure    Larsson, Stieg           2,233,570   \n",
       "13              Romance & Sagas      James, E. L.           2,193,928   \n",
       "14  Crime, Thriller & Adventure        Brown, Dan  2,183,0312,152,737   \n",
       "15          Young Adult Fiction  Meyer, Stephenie           2,062,145   \n",
       "\n",
       "             Publisher  \n",
       "0           Bloomsbury  \n",
       "1           Bloomsbury  \n",
       "2           Bloomsbury  \n",
       "3         Random House  \n",
       "4           Bloomsbury  \n",
       "5           Bloomsbury  \n",
       "6           Bloomsbury  \n",
       "7           Transworld  \n",
       "8           Bloomsbury  \n",
       "9         Random House  \n",
       "10  Little, Brown Book  \n",
       "11             Quercus  \n",
       "12        Random House  \n",
       "13          Transworld  \n",
       "14  Little, Brown Book  \n",
       "15          Transworld  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selling_novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Opening the homepage of imdb.com\n",
    "url= 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "\n",
    "# Extracting name from xpath\n",
    "name=driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "\n",
    "\n",
    "# Extracting year from xpath\n",
    "year=driver.find_elements_by_xpath('//span[@class=\"lister-item-year text-muted unbold\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Year=[]\n",
    "for i in year:\n",
    "    Year.append(i.text)\n",
    "\n",
    "# Extracting genre from xpath\n",
    "genre=driver.find_elements_by_xpath('//span[@class=\"genre\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Genre=[]\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "# Extracting runtime from xpath\n",
    "runtime=driver.find_elements_by_xpath('//span[@class=\"runtime\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them\n",
    "Runtime=[]\n",
    "for i in runtime:\n",
    "    Runtime.append(i.text)\n",
    "\n",
    "\n",
    "# Extracting ratings from xpath\n",
    "ratings=driver.find_elements_by_xpath('//div[@class=\"ipl-rating-star small\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them\n",
    "Ratings=[]\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "\n",
    "# Extracting votes from xpath\n",
    "votes=driver.find_elements_by_xpath('//span[@name=\"nv\"]') \n",
    "# make empty list\n",
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them\n",
    "Votes=[]\n",
    "for i in votes:\n",
    "    Votes.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe\n",
    "TV_serials = pd.DataFrame({'Name':Name,'Year span':Year,'Genre':Genre,\n",
    "                               'Runtime':Runtime,'Ratings':Ratings, 'Votes':Votes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011–2019)</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,835,132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016– )</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>873,915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010–2022)</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>879,210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017–2020)</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014–2020)</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>225,687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign (2013–2017)</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events (2017–2019)</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds (2005–2020)</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>169,554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series (2015–2019)</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>35,118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>193,325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name    Year span  \\\n",
       "0                   1. Game of Thrones (2011–2019)  (2011–2019)   \n",
       "1                      2. Stranger Things (2016– )     (2016– )   \n",
       "2                  3. The Walking Dead (2010–2022)  (2010–2022)   \n",
       "3                    4. 13 Reasons Why (2017–2020)  (2017–2020)   \n",
       "4                           5. The 100 (2014–2020)  (2014–2020)   \n",
       "..                                             ...          ...   \n",
       "95                           96. Reign (2013–2017)  (2013–2017)   \n",
       "96  97. A Series of Unfortunate Events (2017–2019)  (2017–2019)   \n",
       "97                  98. Criminal Minds (2005–2020)  (2005–2020)   \n",
       "98           99. Scream: The TV Series (2015–2019)  (2015–2019)   \n",
       "99          100. The Haunting of Hill House (2018)       (2018)   \n",
       "\n",
       "                       Genre  Runtime Ratings      Votes  \n",
       "0   Action, Adventure, Drama   57 min     9.2  1,835,132  \n",
       "1     Drama, Fantasy, Horror   51 min     8.7    873,915  \n",
       "2    Drama, Horror, Thriller   44 min     8.2    879,210  \n",
       "3   Drama, Mystery, Thriller   60 min     7.6    264,179  \n",
       "4     Drama, Mystery, Sci-Fi   43 min     7.6    225,687  \n",
       "..                       ...      ...     ...        ...  \n",
       "95            Drama, Fantasy   42 min     7.5     44,785  \n",
       "96  Adventure, Comedy, Drama   50 min     7.8     55,390  \n",
       "97     Crime, Drama, Mystery   42 min     8.1    169,554  \n",
       "98      Comedy, Crime, Drama   45 min     7.1     35,118  \n",
       "99    Drama, Horror, Mystery  572 min     8.6    193,325  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_serials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage of uci.edu\n",
    "url= 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting name from xpath\n",
    "dataset_name=driver.find_elements_by_xpath('//p[@class=\"normal\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Dataset_Name=[]\n",
    "for k in dataset_name:\n",
    "    Dataset_Name.append(k.text)    \n",
    "Dataset_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data type from xpath\n",
    "data_type=driver.find_elements_by_xpath('//p[@class=\"normal\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Data_Type=[]\n",
    "for i in data_type:\n",
    "    Data_Type.append(i.text)    \n",
    "Data_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Task from xpath\n",
    "task=driver.find_elements_by_xpath('//p[@class=\"normal\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Task=[]\n",
    "for i in task:\n",
    "    Task.append(i.text)    \n",
    "Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting attribute_type from xpath\n",
    "attribute_type=driver.find_elements_by_xpath('//p[@class=\"normal\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Attribute_type=[]\n",
    "for i in attribute_type:\n",
    "    Attribute_type.append(i.text)    \n",
    "Attribute_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting instance from xpath\n",
    "instance=driver.find_elements_by_xpath('//p[@class=\"normal\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Instance=[]\n",
    "for i in instance:\n",
    "    Instance.append(i.text)    \n",
    "Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting attribute from xpath\n",
    "attribute=driver.find_elements_by_xpath('//p[@class=\"normal\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Attribute=[]\n",
    "for i in attribute:\n",
    "    Attribute.append(i.text)    \n",
    "Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting year from xpath\n",
    "year=driver.find_elements_by_xpath('//p[@class=\"normal\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will run a loop to iterate over the tags extracted above and extract the text inside them.\n",
    "Year=[]\n",
    "for i in year:\n",
    "    Year.append(i.text)    \n",
    "Year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
